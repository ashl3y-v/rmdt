digraph {
	graph [size="424.8,424.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140389348185952 [label="
 ()" fillcolor=darkolivegreen1]
	140389433452112 -> 140389344095712 [dir=none]
	140389344095712 [label="self
 (2, 4)" fillcolor=orange]
	140389433452112 [label="MeanBackward0
------------------------------
self          : [saved tensor]
self_sym_sizes:         (2, 4)"]
	140389433452352 -> 140389433452112
	140389433452352 [label="AddBackward0
------------
alpha: 1"]
	140389433452256 -> 140389433452352
	140389433452256 [label="ExpandBackward0
----------------------
self_sym_sizes: (2, 4)"]
	140389433452064 -> 140389433452256
	140389433452064 -> 140389344092832 [dir=none]
	140389344092832 [label="result
 (2, 4)" fillcolor=orange]
	140389433452064 [label="TanhBackward0
----------------------
result: [saved tensor]"]
	140389433451920 -> 140389433452064
	140389433451920 [label="ReshapeAliasBackward0
-------------------------
self_sym_sizes: (2, 1, 4)"]
	140389433451728 -> 140389433451920
	140389433451728 [label="SliceBackward0
--------------------------
dim           :          2
end           :          4
self_sym_sizes: (2, 1, 20)
start         :          0
step          :          1"]
	140389433451632 -> 140389433451728
	140389433451632 [label="SliceBackward0
-----------------------------------
dim           :                   1
end           : 9223372036854775807
self_sym_sizes:          (2, 1, 20)
start         :                   0
step          :                   1"]
	140389433451344 -> 140389433451632
	140389433451344 [label="SliceBackward0
-----------------------------------
dim           :                   0
end           : 9223372036854775807
self_sym_sizes:          (2, 1, 20)
start         :                   0
step          :                   1"]
	140389433451248 -> 140389433451344
	140389433451248 [label=ToCopyBackward0]
	140389433451152 -> 140389433451248
	140389433451152 [label="SplitWithSizesBackward0
------------------------------------
dim           : 18446744073709551615
self_sym_sizes:           (2, 1, 44)
split_sizes   :          (24, 20, 0)"]
	140389433450864 -> 140389433451152
	140389433450864 [label="SliceBackward0
-----------------------------------
dim           :                   2
end           : 9223372036854775807
self_sym_sizes:          (2, 1, 44)
start         :                   0
step          :                   1"]
	140389433450672 -> 140389433450864
	140389433450672 [label="SliceBackward0
------------------------------------
dim           :                    1
end           :  9223372036854775807
self_sym_sizes:           (2, 8, 44)
start         : 18446744073709551615
step          :                    1"]
	140389433450576 -> 140389433450672
	140389433450576 [label="SliceBackward0
-----------------------------------
dim           :                   0
end           : 9223372036854775807
self_sym_sizes:          (2, 8, 44)
start         :                   0
step          :                   1"]
	140389433450480 -> 140389433450576
	140389433450480 -> 140386053698672 [dir=none]
	140386053698672 [label="bias
 (44)" fillcolor=orange]
	140389433450480 -> 140389344093952 [dir=none]
	140389344093952 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433450480 -> 140389344094672 [dir=none]
	140389344094672 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433450480 -> 140389344088432 [dir=none]
	140389344088432 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433450480 -> 140386053698112 [dir=none]
	140386053698112 [label="weight
 (44)" fillcolor=orange]
	140389433450480 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433450288 -> 140389433450480
	140389433450288 -> 140389436006512 [dir=none]
	140389436006512 [label="bias
 (44)" fillcolor=orange]
	140389433450288 -> 140389344097712 [dir=none]
	140389344097712 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433450288 -> 140389344092752 [dir=none]
	140389344092752 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433450288 -> 140389344091312 [dir=none]
	140389344091312 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433450288 -> 140389436006672 [dir=none]
	140389436006672 [label="weight
 (44)" fillcolor=orange]
	140389433450288 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433450192 -> 140389433450288
	140389433450192 [label="AddBackward0
------------
alpha: 1"]
	140389433450000 -> 140389433450192
	140389433450000 -> 140389436006112 [dir=none]
	140389436006112 [label="bias
 (44)" fillcolor=orange]
	140389433450000 -> 140389344089312 [dir=none]
	140389344089312 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433450000 -> 140389344094112 [dir=none]
	140389344094112 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433450000 -> 140389344093392 [dir=none]
	140389344093392 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433450000 -> 140389436006592 [dir=none]
	140389436006592 [label="weight
 (44)" fillcolor=orange]
	140389433450000 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433449856 -> 140389433450000
	140389433449856 [label="AddBackward0
------------
alpha: 1"]
	140389433449712 -> 140389433449856
	140389433449712 -> 140389436005552 [dir=none]
	140389436005552 [label="bias
 (44)" fillcolor=orange]
	140389433449712 -> 140389344100032 [dir=none]
	140389344100032 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433449712 -> 140389344093792 [dir=none]
	140389344093792 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433449712 -> 140389344093472 [dir=none]
	140389344093472 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433449712 -> 140389436005712 [dir=none]
	140389436005712 [label="weight
 (44)" fillcolor=orange]
	140389433449712 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433449520 -> 140389433449712
	140389433449520 [label="AddBackward0
------------
alpha: 1"]
	140389433449328 -> 140389433449520
	140389433449328 -> 140389436005152 [dir=none]
	140389436005152 [label="bias
 (44)" fillcolor=orange]
	140389433449328 -> 140389344094192 [dir=none]
	140389344094192 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433449328 -> 140389344093632 [dir=none]
	140389344093632 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433449328 -> 140389344093312 [dir=none]
	140389344093312 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433449328 -> 140389436005632 [dir=none]
	140389436005632 [label="weight
 (44)" fillcolor=orange]
	140389433449328 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433449184 -> 140389433449328
	140389433449184 [label="AddBackward0
------------
alpha: 1"]
	140389433449088 -> 140389433449184
	140389433449088 -> 140389436004592 [dir=none]
	140389436004592 [label="bias
 (44)" fillcolor=orange]
	140389433449088 -> 140389344099312 [dir=none]
	140389344099312 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433449088 -> 140389344090272 [dir=none]
	140389344090272 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433449088 -> 140389344093712 [dir=none]
	140389344093712 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433449088 -> 140389436004752 [dir=none]
	140389436004752 [label="weight
 (44)" fillcolor=orange]
	140389433449088 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433448944 -> 140389433449088
	140389433448944 [label="AddBackward0
------------
alpha: 1"]
	140389433448800 -> 140389433448944
	140389433448800 -> 140389436004192 [dir=none]
	140389436004192 [label="bias
 (44)" fillcolor=orange]
	140389433448800 -> 140389344091712 [dir=none]
	140389344091712 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433448800 -> 140389344090352 [dir=none]
	140389344090352 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433448800 -> 140389344093552 [dir=none]
	140389344093552 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433448800 -> 140389436004672 [dir=none]
	140389436004672 [label="weight
 (44)" fillcolor=orange]
	140389433448800 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433448656 -> 140389433448800
	140389433448656 [label="AddBackward0
------------
alpha: 1"]
	140389433448512 -> 140389433448656
	140389433448512 -> 140389436003632 [dir=none]
	140389436003632 [label="bias
 (44)" fillcolor=orange]
	140389433448512 -> 140389344096512 [dir=none]
	140389344096512 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433448512 -> 140389344091072 [dir=none]
	140389344091072 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433448512 -> 140389344089472 [dir=none]
	140389344089472 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433448512 -> 140389436003792 [dir=none]
	140389436003792 [label="weight
 (44)" fillcolor=orange]
	140389433448512 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433448320 -> 140389433448512
	140389433448320 [label="AddBackward0
------------
alpha: 1"]
	140389433448224 -> 140389433448320
	140389433448224 -> 140389436003232 [dir=none]
	140389436003232 [label="bias
 (44)" fillcolor=orange]
	140389433448224 -> 140389344090512 [dir=none]
	140389344090512 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433448224 -> 140389344091152 [dir=none]
	140389344091152 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433448224 -> 140389344089552 [dir=none]
	140389344089552 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433448224 -> 140389436003712 [dir=none]
	140389436003712 [label="weight
 (44)" fillcolor=orange]
	140389433448224 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433448080 -> 140389433448224
	140389433448080 [label="AddBackward0
------------
alpha: 1"]
	140389433447984 -> 140389433448080
	140389433447984 -> 140389436002672 [dir=none]
	140389436002672 [label="bias
 (44)" fillcolor=orange]
	140389433447984 -> 140389344098752 [dir=none]
	140389344098752 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433447984 -> 140389344090752 [dir=none]
	140389344090752 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433447984 -> 140389344090912 [dir=none]
	140389344090912 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433447984 -> 140389436002832 [dir=none]
	140389436002832 [label="weight
 (44)" fillcolor=orange]
	140389433447984 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433447840 -> 140389433447984
	140389433447840 [label="AddBackward0
------------
alpha: 1"]
	140389433447744 -> 140389433447840
	140389433447744 -> 140389436002272 [dir=none]
	140389436002272 [label="bias
 (44)" fillcolor=orange]
	140389433447744 -> 140389344096272 [dir=none]
	140389344096272 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433447744 -> 140389344090832 [dir=none]
	140389344090832 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433447744 -> 140389344090992 [dir=none]
	140389344090992 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433447744 -> 140389436002752 [dir=none]
	140389436002752 [label="weight
 (44)" fillcolor=orange]
	140389433447744 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433447600 -> 140389433447744
	140389433447600 [label="AddBackward0
------------
alpha: 1"]
	140389433447504 -> 140389433447600
	140389433447504 -> 140389436001712 [dir=none]
	140389436001712 [label="bias
 (44)" fillcolor=orange]
	140389433447504 -> 140389344099632 [dir=none]
	140389344099632 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433447504 -> 140389344090592 [dir=none]
	140389344090592 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433447504 -> 140389344090672 [dir=none]
	140389344090672 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433447504 -> 140389436001872 [dir=none]
	140389436001872 [label="weight
 (44)" fillcolor=orange]
	140389433447504 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433447360 -> 140389433447504
	140389433447360 [label="AddBackward0
------------
alpha: 1"]
	140389433447264 -> 140389433447360
	140389433447264 -> 140389436001312 [dir=none]
	140389436001312 [label="bias
 (44)" fillcolor=orange]
	140389433447264 -> 140389344098112 [dir=none]
	140389344098112 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433447264 -> 140389348069584 [dir=none]
	140389348069584 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433447264 -> 140389348069744 [dir=none]
	140389348069744 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433447264 -> 140389436001792 [dir=none]
	140389436001792 [label="weight
 (44)" fillcolor=orange]
	140389433447264 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433447120 -> 140389433447264
	140389433447120 [label="AddBackward0
------------
alpha: 1"]
	140389433446928 -> 140389433447120
	140389433446928 -> 140389436000752 [dir=none]
	140389436000752 [label="bias
 (44)" fillcolor=orange]
	140389433446928 -> 140389344098432 [dir=none]
	140389344098432 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433446928 -> 140389348067584 [dir=none]
	140389348067584 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433446928 -> 140389348069664 [dir=none]
	140389348069664 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433446928 -> 140389436000912 [dir=none]
	140389436000912 [label="weight
 (44)" fillcolor=orange]
	140389433446928 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433446784 -> 140389433446928
	140389433446784 [label="AddBackward0
------------
alpha: 1"]
	140389433446640 -> 140389433446784
	140389433446640 -> 140389436000352 [dir=none]
	140389436000352 [label="bias
 (44)" fillcolor=orange]
	140389433446640 -> 140389344098832 [dir=none]
	140389344098832 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433446640 -> 140389348067744 [dir=none]
	140389348067744 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433446640 -> 140389348069344 [dir=none]
	140389348069344 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433446640 -> 140389436000832 [dir=none]
	140389436000832 [label="weight
 (44)" fillcolor=orange]
	140389433446640 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433446496 -> 140389433446640
	140389433446496 [label="AddBackward0
------------
alpha: 1"]
	140389433446304 -> 140389433446496
	140389433446304 -> 140389435999792 [dir=none]
	140389435999792 [label="bias
 (44)" fillcolor=orange]
	140389433446304 -> 140389344098272 [dir=none]
	140389344098272 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433446304 -> 140389348069184 [dir=none]
	140389348069184 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433446304 -> 140389348068304 [dir=none]
	140389348068304 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433446304 -> 140389435999952 [dir=none]
	140389435999952 [label="weight
 (44)" fillcolor=orange]
	140389433446304 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433446160 -> 140389433446304
	140389433446160 [label="AddBackward0
------------
alpha: 1"]
	140389433446064 -> 140389433446160
	140389433446064 -> 140389435999392 [dir=none]
	140389435999392 [label="bias
 (44)" fillcolor=orange]
	140389433446064 -> 140389344096832 [dir=none]
	140389344096832 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433446064 -> 140389348069264 [dir=none]
	140389348069264 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433446064 -> 140389348068384 [dir=none]
	140389348068384 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433446064 -> 140389435999872 [dir=none]
	140389435999872 [label="weight
 (44)" fillcolor=orange]
	140389433446064 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433445920 -> 140389433446064
	140389433445920 [label="AddBackward0
------------
alpha: 1"]
	140389433445824 -> 140389433445920
	140389433445824 -> 140389435998832 [dir=none]
	140389435998832 [label="bias
 (44)" fillcolor=orange]
	140389433445824 -> 140389344098512 [dir=none]
	140389344098512 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433445824 -> 140389348067904 [dir=none]
	140389348067904 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433445824 -> 140389348068464 [dir=none]
	140389348068464 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433445824 -> 140389435998992 [dir=none]
	140389435998992 [label="weight
 (44)" fillcolor=orange]
	140389433445824 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433445584 -> 140389433445824
	140389433445584 [label="AddBackward0
------------
alpha: 1"]
	140389433445248 -> 140389433445584
	140389433445248 -> 140389435998432 [dir=none]
	140389435998432 [label="bias
 (44)" fillcolor=orange]
	140389433445248 -> 140389344099552 [dir=none]
	140389344099552 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433445248 -> 140389348070064 [dir=none]
	140389348070064 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433445248 -> 140389348069904 [dir=none]
	140389348069904 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433445248 -> 140389435998912 [dir=none]
	140389435998912 [label="weight
 (44)" fillcolor=orange]
	140389433445248 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433445104 -> 140389433445248
	140389433445104 [label="AddBackward0
------------
alpha: 1"]
	140389433445008 -> 140389433445104
	140389433445008 -> 140386053701232 [dir=none]
	140386053701232 [label="bias
 (44)" fillcolor=orange]
	140389433445008 -> 140389344099872 [dir=none]
	140389344099872 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433445008 -> 140389348068944 [dir=none]
	140389348068944 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433445008 -> 140389348069984 [dir=none]
	140389348069984 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433445008 -> 140386053701392 [dir=none]
	140386053701392 [label="weight
 (44)" fillcolor=orange]
	140389433445008 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433444864 -> 140389433445008
	140389433444864 [label="AddBackward0
------------
alpha: 1"]
	140389433444768 -> 140389433444864
	140389433444768 -> 140386053700832 [dir=none]
	140386053700832 [label="bias
 (44)" fillcolor=orange]
	140389433444768 -> 140389344098192 [dir=none]
	140389344098192 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433444768 -> 140389348065744 [dir=none]
	140389348065744 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433444768 -> 140389348069824 [dir=none]
	140389348069824 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433444768 -> 140386053701312 [dir=none]
	140386053701312 [label="weight
 (44)" fillcolor=orange]
	140389433444768 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433444624 -> 140389433444768
	140389433444624 [label="AddBackward0
------------
alpha: 1"]
	140389433444528 -> 140389433444624
	140389433444528 -> 140386053700432 [dir=none]
	140386053700432 [label="bias
 (44)" fillcolor=orange]
	140389433444528 -> 140389348067664 [dir=none]
	140389348067664 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433444528 -> 140389348065824 [dir=none]
	140389348065824 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433444528 -> 140389348067504 [dir=none]
	140389348067504 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433444528 -> 140386053700352 [dir=none]
	140386053700352 [label="weight
 (44)" fillcolor=orange]
	140389433444528 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433444384 -> 140389433444528
	140389433444384 [label="AddBackward0
------------
alpha: 1"]
	140389433444288 -> 140389433444384
	140389433444288 -> 140386053698832 [dir=none]
	140386053698832 [label="bias
 (44)" fillcolor=orange]
	140389433444288 -> 140389348068544 [dir=none]
	140389348068544 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433444288 -> 140389348066144 [dir=none]
	140389348066144 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433444288 -> 140389348065584 [dir=none]
	140389348065584 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433444288 -> 140386053700192 [dir=none]
	140386053700192 [label="weight
 (44)" fillcolor=orange]
	140389433444288 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433444096 -> 140389433444288
	140389433444096 [label="AddBackward0
------------
alpha: 1"]
	140389433443904 -> 140389433444096
	140389433443904 -> 140386053699232 [dir=none]
	140386053699232 [label="bias
 (44)" fillcolor=orange]
	140389433443904 -> 140389344095792 [dir=none]
	140389344095792 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433443904 -> 140389348066224 [dir=none]
	140389348066224 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433443904 -> 140389348065664 [dir=none]
	140389348065664 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433443904 -> 140386053699872 [dir=none]
	140386053699872 [label="weight
 (44)" fillcolor=orange]
	140389433443904 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433443712 -> 140389433443904
	140389433443712 [label="AddBackward0
------------
alpha: 1"]
	140389433443616 -> 140389433443712
	140389433443616 -> 140386053699472 [dir=none]
	140386053699472 [label="bias
 (44)" fillcolor=orange]
	140389433443616 -> 140389350148592 [dir=none]
	140389350148592 [label="input
 (2, 8, 44)" fillcolor=orange]
	140389433443616 -> 140389348066064 [dir=none]
	140389348066064 [label="result1
 (2, 8, 1)" fillcolor=orange]
	140389433443616 -> 140389348066304 [dir=none]
	140389348066304 [label="result2
 (2, 8, 1)" fillcolor=orange]
	140389433443616 -> 140386053699952 [dir=none]
	140386053699952 [label="weight
 (44)" fillcolor=orange]
	140389433443616 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (44,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	140389433443472 -> 140389433443616
	140389433443472 [label="AddBackward0
------------
alpha: 1"]
	140389433443376 -> 140389433443472
	140389433443376 -> 140389348066544 [dir=none]
	140389348066544 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433443376 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433443232 -> 140389433443376
	140389433443232 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433443136 -> 140389433443232
	140389433443136 -> 140389348068704 [dir=none]
	140389348068704 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433443136 -> 140389348066464 [dir=none]
	140389348066464 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433443136 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433318352 -> 140389433443136
	140386053699632 [label="transformer.layers.0.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140386053699632 -> 140389433318352
	140389433318352 [label=AccumulateGrad]
	140389433443040 -> 140389433443136
	140389433443040 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389433442992 -> 140389433443040
	140389433442992 [label=CloneBackward0]
	140389433442800 -> 140389433442992
	140389433442800 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389433442656 -> 140389433442800
	140389433442656 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389433447024 -> 140389433442656
	140389433447024 -> 140389348066384 [dir=none]
	140389348066384 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389433447024 -> 140389348065984 [dir=none]
	140389348065984 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389433447024 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389433449760 -> 140389433447024
	140389433449760 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389433458064 -> 140389433449760
	140389433458064 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389433457728 -> 140389433458064
	140389433457728 -> 140389348065904 [dir=none]
	140389348065904 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389433457728 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308334288 -> 140389433457728
	140389308334288 -> 140389348067344 [dir=none]
	140389348067344 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308334288 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308334384 -> 140389308334288
	140389308334384 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308334480 -> 140389308334384
	140389308334480 -> 140389348067424 [dir=none]
	140389348067424 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308334480 -> 140389348067264 [dir=none]
	140389348067264 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308334480 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308334576 -> 140389308334480
	140389308334576 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308334720 -> 140389308334576
	140389308334720 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308334816 -> 140389308334720
	140389308334816 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308334912 -> 140389308334816
	140389308334912 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308335008 -> 140389308334912
	140389308335008 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308335104 -> 140389308335008
	140389308335104 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308335200 -> 140389308335104
	140389308335200 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308335296 -> 140389308335200
	140389308335296 [label=CloneBackward0]
	140389308335392 -> 140389308335296
	140389308335392 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308335536 -> 140389308335392
	140389308335536 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308335680 -> 140389308335536
	140389308335680 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308335728 -> 140389308335680
	140389308335728 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308335872 -> 140389308335728
	140389308335872 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308335968 -> 140389308335872
	140389308335968 -> 140389348067104 [dir=none]
	140389348067104 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308335968 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:             ()
mat2            :           None
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389433315424 -> 140389308335968
	140386053699152 [label="transformer.layers.0.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140386053699152 -> 140389433315424
	140389433315424 [label=AccumulateGrad]
	140389308336064 -> 140389308335968
	140389308336064 [label=TBackward0]
	140389433315376 -> 140389308336064
	140386053699312 [label="transformer.layers.0.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140386053699312 -> 140389433315376
	140389433315376 [label=AccumulateGrad]
	140389308334528 -> 140389308334480
	140389308334528 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308334864 -> 140389308334528
	140389308334864 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308335056 -> 140389308334864
	140389308335056 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308335248 -> 140389308335056
	140389308335248 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308335584 -> 140389308335248
	140389308335584 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308335632 -> 140389308335584
	140389308335632 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308335920 -> 140389308335632
	140389308335920 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308334624 -> 140389308335920
	140389308334624 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308335296 -> 140389308334624
	140389433446400 -> 140389433447024
	140389433446400 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389433457152 -> 140389433446400
	140389433457152 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308334432 -> 140389433457152
	140389308334432 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308334768 -> 140389308334432
	140389308334768 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308335152 -> 140389308334768
	140389308335152 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308335344 -> 140389308335152
	140389308335344 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308335296 -> 140389308335344
	140389433443088 -> 140389433443136
	140389433443088 [label=TBackward0]
	140389433317920 -> 140389433443088
	140386053699792 [label="transformer.layers.0.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140386053699792 -> 140389433317920
	140389433317920 [label=AccumulateGrad]
	140389433319120 -> 140389433443616
	140386053699952 [label="transformer.layers.0.norm1.weight
 (44)" fillcolor=lightblue]
	140386053699952 -> 140389433319120
	140389433319120 [label=AccumulateGrad]
	140389433319168 -> 140389433443616
	140386053699472 [label="transformer.layers.0.norm1.bias
 (44)" fillcolor=lightblue]
	140386053699472 -> 140389433319168
	140389433319168 [label=AccumulateGrad]
	140389433443664 -> 140389433443712
	140389433443664 -> 140389348066624 [dir=none]
	140389348066624 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433443664 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433443328 -> 140389433443664
	140389433443328 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433443568 -> 140389433443328
	140389433443568 -> 140389348066864 [dir=none]
	140389348066864 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433443568 -> 140389348067184 [dir=none]
	140389348067184 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433443568 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389433318064 -> 140389433443568
	140386053698992 [label="transformer.layers.0.linear2.bias
 (44)" fillcolor=lightblue]
	140386053698992 -> 140389433318064
	140389433318064 [label=AccumulateGrad]
	140389433442560 -> 140389433443568
	140389433442560 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389433442944 -> 140389433442560
	140389433442944 -> 140389348066704 [dir=none]
	140389348066704 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389433442944 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433442896 -> 140389433442944
	140389433442896 -> 140389344088832 [dir=none]
	140389344088832 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389433442896 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308334960 -> 140389433442896
	140389308334960 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308335776 -> 140389308334960
	140389308335776 -> 140389348065504 [dir=none]
	140389348065504 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308335776 -> 140389348066784 [dir=none]
	140389348066784 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308335776 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389433315232 -> 140389308335776
	140386053699072 [label="transformer.layers.0.linear1.bias
 (2048)" fillcolor=lightblue]
	140386053699072 -> 140389433315232
	140389433315232 [label=AccumulateGrad]
	140389308334192 -> 140389308335776
	140389308334192 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433443616 -> 140389308334192
	140389308335824 -> 140389308335776
	140389308335824 [label=TBackward0]
	140389433315136 -> 140389308335824
	140386053699392 [label="transformer.layers.0.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140386053699392 -> 140389433315136
	140389433315136 [label=AccumulateGrad]
	140389433442752 -> 140389433443568
	140389433442752 [label=TBackward0]
	140389433316144 -> 140389433442752
	140386053699552 [label="transformer.layers.0.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140386053699552 -> 140389433316144
	140389433316144 [label=AccumulateGrad]
	140389433319504 -> 140389433443904
	140386053699872 [label="transformer.layers.0.norm2.weight
 (44)" fillcolor=lightblue]
	140386053699872 -> 140389433319504
	140389433319504 [label=AccumulateGrad]
	140389433319552 -> 140389433443904
	140386053699232 [label="transformer.layers.0.norm2.bias
 (44)" fillcolor=lightblue]
	140386053699232 -> 140389433319552
	140389433319552 [label=AccumulateGrad]
	140389433444048 -> 140389433444096
	140389433444048 -> 140389348065424 [dir=none]
	140389348065424 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433444048 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433443424 -> 140389433444048
	140389433443424 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433443520 -> 140389433443424
	140389433443520 -> 140389348069424 [dir=none]
	140389348069424 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433443520 -> 140389348065344 [dir=none]
	140389348065344 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433443520 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433315184 -> 140389433443520
	140386053700112 [label="transformer.layers.1.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140386053700112 -> 140389433315184
	140389433315184 [label=AccumulateGrad]
	140389433442848 -> 140389433443520
	140389433442848 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308334336 -> 140389433442848
	140389308334336 [label=CloneBackward0]
	140389308334672 -> 140389308334336
	140389308334672 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308336160 -> 140389308334672
	140389308336160 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308336256 -> 140389308336160
	140389308336256 -> 140389348067824 [dir=none]
	140389348067824 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308336256 -> 140389348066944 [dir=none]
	140389348066944 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308336256 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308336352 -> 140389308336256
	140389308336352 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308336496 -> 140389308336352
	140389308336496 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308336592 -> 140389308336496
	140389308336592 -> 140389348067024 [dir=none]
	140389348067024 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308336592 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308336688 -> 140389308336592
	140389308336688 -> 140389348070224 [dir=none]
	140389348070224 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308336688 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308336784 -> 140389308336688
	140389308336784 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308336880 -> 140389308336784
	140389308336880 -> 140389348070384 [dir=none]
	140389348070384 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308336880 -> 140389348070464 [dir=none]
	140389348070464 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308336880 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308336976 -> 140389308336880
	140389308336976 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308337120 -> 140389308336976
	140389308337120 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308337216 -> 140389308337120
	140389308337216 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308337312 -> 140389308337216
	140389308337312 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308337408 -> 140389308337312
	140389308337408 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308337504 -> 140389308337408
	140389308337504 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308337600 -> 140389308337504
	140389308337600 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308337696 -> 140389308337600
	140389308337696 [label=CloneBackward0]
	140389308337792 -> 140389308337696
	140389308337792 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308337888 -> 140389308337792
	140389308337888 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308338032 -> 140389308337888
	140389308338032 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308338080 -> 140389308338032
	140389308338080 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308338224 -> 140389308338080
	140389308338224 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308338320 -> 140389308338224
	140389308338320 -> 140389348070144 [dir=none]
	140389348070144 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308338320 -> 140389348070704 [dir=none]
	140389348070704 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308338320 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389433311968 -> 140389308338320
	140386053698752 [label="transformer.layers.1.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140386053698752 -> 140389433311968
	140389433311968 [label=AccumulateGrad]
	140389308338416 -> 140389308338320
	140389308338416 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433443904 -> 140389308338416
	140389308338368 -> 140389308338320
	140389308338368 [label=TBackward0]
	140389433311728 -> 140389308338368
	140386053698912 [label="transformer.layers.1.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140386053698912 -> 140389433311728
	140389433311728 [label=AccumulateGrad]
	140389308336928 -> 140389308336880
	140389308336928 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308337264 -> 140389308336928
	140389308337264 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308337456 -> 140389308337264
	140389308337456 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308337648 -> 140389308337456
	140389308337648 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308337936 -> 140389308337648
	140389308337936 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308337984 -> 140389308337936
	140389308337984 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308338272 -> 140389308337984
	140389308338272 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308338560 -> 140389308338272
	140389308338560 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308337696 -> 140389308338560
	140389308336304 -> 140389308336256
	140389308336304 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308336640 -> 140389308336304
	140389308336640 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308336832 -> 140389308336640
	140389308336832 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308337168 -> 140389308336832
	140389308337168 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308337552 -> 140389308337168
	140389308337552 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308337744 -> 140389308337552
	140389308337744 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308337696 -> 140389308337744
	140389433443808 -> 140389433443520
	140389433443808 [label=TBackward0]
	140389433314944 -> 140389433443808
	140386053700272 [label="transformer.layers.1.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140386053700272 -> 140389433314944
	140389433314944 [label=AccumulateGrad]
	140389433319840 -> 140389433444288
	140386053700192 [label="transformer.layers.1.norm1.weight
 (44)" fillcolor=lightblue]
	140386053700192 -> 140389433319840
	140389433319840 [label=AccumulateGrad]
	140389433319888 -> 140389433444288
	140386053698832 [label="transformer.layers.1.norm1.bias
 (44)" fillcolor=lightblue]
	140386053698832 -> 140389433319888
	140389433319888 [label=AccumulateGrad]
	140389433444336 -> 140389433444384
	140389433444336 -> 140389348070304 [dir=none]
	140389348070304 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433444336 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433443856 -> 140389433444336
	140389433443856 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433443184 -> 140389433443856
	140389433443184 -> 140389348070784 [dir=none]
	140389348070784 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433443184 -> 140389348070624 [dir=none]
	140389348070624 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433443184 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389433314992 -> 140389433443184
	140386053700032 [label="transformer.layers.1.linear2.bias
 (44)" fillcolor=lightblue]
	140386053700032 -> 140389433314992
	140389433314992 [label=AccumulateGrad]
	140389308336112 -> 140389433443184
	140389308336112 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308334144 -> 140389308336112
	140389308334144 -> 140389348070544 [dir=none]
	140389348070544 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308334144 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308336736 -> 140389308334144
	140389308336736 -> 140389348069104 [dir=none]
	140389348069104 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308336736 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308337360 -> 140389308336736
	140389308337360 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308338128 -> 140389308337360
	140389308338128 -> 140389348071104 [dir=none]
	140389348071104 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308338128 -> 140389348070864 [dir=none]
	140389348070864 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308338128 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389433311680 -> 140389308338128
	140386053699712 [label="transformer.layers.1.linear1.bias
 (2048)" fillcolor=lightblue]
	140386053699712 -> 140389433311680
	140389433311680 [label=AccumulateGrad]
	140389308336448 -> 140389308338128
	140389308336448 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433444288 -> 140389308336448
	140389308338176 -> 140389308338128
	140389308338176 [label=TBackward0]
	140389433311584 -> 140389308338176
	140386173612368 [label="transformer.layers.1.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140386173612368 -> 140389433311584
	140389433311584 [label=AccumulateGrad]
	140389308336016 -> 140389433443184
	140389308336016 [label=TBackward0]
	140389433312640 -> 140389308336016
	140386175215760 [label="transformer.layers.1.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140386175215760 -> 140389433312640
	140389433312640 [label=AccumulateGrad]
	140389433320176 -> 140389433444528
	140386053700352 [label="transformer.layers.1.norm2.weight
 (44)" fillcolor=lightblue]
	140386053700352 -> 140389433320176
	140389433320176 [label=AccumulateGrad]
	140389433320224 -> 140389433444528
	140386053700432 [label="transformer.layers.1.norm2.bias
 (44)" fillcolor=lightblue]
	140386053700432 -> 140389433320224
	140389433320224 [label=AccumulateGrad]
	140389433444576 -> 140389433444624
	140389433444576 -> 140389348071184 [dir=none]
	140389348071184 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433444576 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433444240 -> 140389433444576
	140389433444240 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433444144 -> 140389433444240
	140389433444144 -> 140389350149152 [dir=none]
	140389350149152 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433444144 -> 140389348071264 [dir=none]
	140389348071264 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433444144 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433311632 -> 140389433444144
	140386053700992 [label="transformer.layers.2.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140386053700992 -> 140389433311632
	140389433311632 [label=AccumulateGrad]
	140389308337840 -> 140389433444144
	140389308337840 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308336208 -> 140389308337840
	140389308336208 [label=CloneBackward0]
	140389308337072 -> 140389308336208
	140389308337072 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308338464 -> 140389308337072
	140389308338464 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308338656 -> 140389308338464
	140389308338656 -> 140389348071344 [dir=none]
	140389348071344 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308338656 -> 140389348071024 [dir=none]
	140389348071024 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308338656 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308338752 -> 140389308338656
	140389308338752 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308338896 -> 140389308338752
	140389308338896 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308338992 -> 140389308338896
	140389308338992 -> 140389348070944 [dir=none]
	140389348070944 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308338992 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308339088 -> 140389308338992
	140389308339088 -> 140389348071504 [dir=none]
	140389348071504 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308339088 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308339184 -> 140389308339088
	140389308339184 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308339280 -> 140389308339184
	140389308339280 -> 140389348071664 [dir=none]
	140389348071664 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308339280 -> 140389348071744 [dir=none]
	140389348071744 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308339280 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308339376 -> 140389308339280
	140389308339376 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308339520 -> 140389308339376
	140389308339520 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308339616 -> 140389308339520
	140389308339616 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308339712 -> 140389308339616
	140389308339712 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308339808 -> 140389308339712
	140389308339808 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308339904 -> 140389308339808
	140389308339904 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308340000 -> 140389308339904
	140389308340000 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308340096 -> 140389308340000
	140389308340096 [label=CloneBackward0]
	140389308340192 -> 140389308340096
	140389308340192 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308340288 -> 140389308340192
	140389308340288 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308340432 -> 140389308340288
	140389308340432 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308340480 -> 140389308340432
	140389308340480 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308340624 -> 140389308340480
	140389308340624 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308340720 -> 140389308340624
	140389308340720 -> 140389348071424 [dir=none]
	140389348071424 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308340720 -> 140389348071984 [dir=none]
	140389348071984 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308340720 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389435979952 -> 140389308340720
	140386053700512 [label="transformer.layers.2.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140386053700512 -> 140389435979952
	140389435979952 [label=AccumulateGrad]
	140389308340816 -> 140389308340720
	140389308340816 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433444528 -> 140389308340816
	140389308340768 -> 140389308340720
	140389308340768 [label=TBackward0]
	140389435979712 -> 140389308340768
	140386053700592 [label="transformer.layers.2.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140386053700592 -> 140389435979712
	140389435979712 [label=AccumulateGrad]
	140389308339328 -> 140389308339280
	140389308339328 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308339664 -> 140389308339328
	140389308339664 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308339856 -> 140389308339664
	140389308339856 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308340048 -> 140389308339856
	140389308340048 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308340336 -> 140389308340048
	140389308340336 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308340384 -> 140389308340336
	140389308340384 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308340672 -> 140389308340384
	140389308340672 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308340960 -> 140389308340672
	140389308340960 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308340096 -> 140389308340960
	140389308338704 -> 140389308338656
	140389308338704 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308339040 -> 140389308338704
	140389308339040 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308339232 -> 140389308339040
	140389308339232 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308339568 -> 140389308339232
	140389308339568 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308339952 -> 140389308339568
	140389308339952 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308340144 -> 140389308339952
	140389308340144 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308340096 -> 140389308340144
	140389308336400 -> 140389433444144
	140389308336400 [label=TBackward0]
	140389433311392 -> 140389308336400
	140386053701152 [label="transformer.layers.2.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140386053701152 -> 140389433311392
	140389433311392 [label=AccumulateGrad]
	140389433320512 -> 140389433444768
	140386053701312 [label="transformer.layers.2.norm1.weight
 (44)" fillcolor=lightblue]
	140386053701312 -> 140389433320512
	140389433320512 [label=AccumulateGrad]
	140389433320560 -> 140389433444768
	140386053700832 [label="transformer.layers.2.norm1.bias
 (44)" fillcolor=lightblue]
	140386053700832 -> 140389433320560
	140389433320560 [label=AccumulateGrad]
	140389433444816 -> 140389433444864
	140389433444816 -> 140389348071584 [dir=none]
	140389348071584 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433444816 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433444480 -> 140389433444816
	140389433444480 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433444432 -> 140389433444480
	140389433444432 -> 140389348072064 [dir=none]
	140389348072064 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433444432 -> 140389348071904 [dir=none]
	140389348071904 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433444432 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389433311488 -> 140389433444432
	140386053700912 [label="transformer.layers.2.linear2.bias
 (44)" fillcolor=lightblue]
	140386053700912 -> 140389433311488
	140389433311488 [label=AccumulateGrad]
	140389308338512 -> 140389433444432
	140389308338512 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308336544 -> 140389308338512
	140389308336544 -> 140389348071824 [dir=none]
	140389348071824 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308336544 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308339136 -> 140389308336544
	140389308339136 -> 140389344098352 [dir=none]
	140389344098352 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308339136 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308339760 -> 140389308339136
	140389308339760 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308340528 -> 140389308339760
	140389308340528 -> 140389348072384 [dir=none]
	140389348072384 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308340528 -> 140389348072144 [dir=none]
	140389348072144 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308340528 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389435979664 -> 140389308340528
	140386053700672 [label="transformer.layers.2.linear1.bias
 (2048)" fillcolor=lightblue]
	140386053700672 -> 140389435979664
	140389435979664 [label=AccumulateGrad]
	140389308338848 -> 140389308340528
	140389308338848 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433444768 -> 140389308338848
	140389308340576 -> 140389308340528
	140389308340576 [label=TBackward0]
	140389435979568 -> 140389308340576
	140386053700752 [label="transformer.layers.2.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140386053700752 -> 140389435979568
	140389435979568 [label=AccumulateGrad]
	140389308337024 -> 140389433444432
	140389308337024 [label=TBackward0]
	140389435980672 -> 140389308337024
	140386053701072 [label="transformer.layers.2.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140386053701072 -> 140389435980672
	140389435980672 [label=AccumulateGrad]
	140389433320848 -> 140389433445008
	140386053701392 [label="transformer.layers.2.norm2.weight
 (44)" fillcolor=lightblue]
	140386053701392 -> 140389433320848
	140389433320848 [label=AccumulateGrad]
	140389433320896 -> 140389433445008
	140386053701232 [label="transformer.layers.2.norm2.bias
 (44)" fillcolor=lightblue]
	140386053701232 -> 140389433320896
	140389433320896 [label=AccumulateGrad]
	140389433445056 -> 140389433445104
	140389433445056 -> 140389348072464 [dir=none]
	140389348072464 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433445056 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433444720 -> 140389433445056
	140389433444720 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433444672 -> 140389433444720
	140389433444672 -> 140389344096592 [dir=none]
	140389344096592 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433444672 -> 140389348072544 [dir=none]
	140389348072544 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433444672 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433320752 -> 140389433444672
	140389435998592 [label="transformer.layers.3.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389435998592 -> 140389433320752
	140389433320752 [label=AccumulateGrad]
	140389308340240 -> 140389433444672
	140389308340240 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308338608 -> 140389308340240
	140389308338608 [label=CloneBackward0]
	140389308339472 -> 140389308338608
	140389308339472 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308340864 -> 140389308339472
	140389308340864 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308341056 -> 140389308340864
	140389308341056 -> 140389348072624 [dir=none]
	140389348072624 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308341056 -> 140389348072304 [dir=none]
	140389348072304 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308341056 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308341152 -> 140389308341056
	140389308341152 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308341296 -> 140389308341152
	140389308341296 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308341392 -> 140389308341296
	140389308341392 -> 140389348072224 [dir=none]
	140389348072224 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308341392 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308341488 -> 140389308341392
	140389308341488 -> 140389348072784 [dir=none]
	140389348072784 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308341488 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308341584 -> 140389308341488
	140389308341584 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308341680 -> 140389308341584
	140389308341680 -> 140389348072944 [dir=none]
	140389348072944 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308341680 -> 140389348073024 [dir=none]
	140389348073024 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308341680 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308341776 -> 140389308341680
	140389308341776 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308341920 -> 140389308341776
	140389308341920 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308342016 -> 140389308341920
	140389308342016 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308342112 -> 140389308342016
	140389308342112 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308342208 -> 140389308342112
	140389308342208 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308342304 -> 140389308342208
	140389308342304 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308342400 -> 140389308342304
	140389308342400 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308342496 -> 140389308342400
	140389308342496 [label=CloneBackward0]
	140389308342592 -> 140389308342496
	140389308342592 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308342688 -> 140389308342592
	140389308342688 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308342832 -> 140389308342688
	140389308342832 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308342880 -> 140389308342832
	140389308342880 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308343024 -> 140389308342880
	140389308343024 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308343120 -> 140389308343024
	140389308343120 -> 140389348072704 [dir=none]
	140389348072704 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308343120 -> 140389348073264 [dir=none]
	140389348073264 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308343120 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389429944160 -> 140389308343120
	140389435998272 [label="transformer.layers.3.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389435998272 -> 140389429944160
	140389429944160 [label=AccumulateGrad]
	140389308343216 -> 140389308343120
	140389308343216 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433445008 -> 140389308343216
	140389308343168 -> 140389308343120
	140389308343168 [label=TBackward0]
	140389429948960 -> 140389308343168
	140386053701472 [label="transformer.layers.3.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140386053701472 -> 140389429948960
	140389429948960 [label=AccumulateGrad]
	140389308341728 -> 140389308341680
	140389308341728 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308342064 -> 140389308341728
	140389308342064 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308342256 -> 140389308342064
	140389308342256 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308342448 -> 140389308342256
	140389308342448 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308342736 -> 140389308342448
	140389308342736 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308342784 -> 140389308342736
	140389308342784 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308343072 -> 140389308342784
	140389308343072 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308343360 -> 140389308343072
	140389308343360 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308342496 -> 140389308343360
	140389308341104 -> 140389308341056
	140389308341104 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308341440 -> 140389308341104
	140389308341440 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308341632 -> 140389308341440
	140389308341632 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308341968 -> 140389308341632
	140389308341968 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308342352 -> 140389308341968
	140389308342352 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308342544 -> 140389308342352
	140389308342544 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308342496 -> 140389308342544
	140389308338800 -> 140389433444672
	140389308338800 [label=TBackward0]
	140389435979424 -> 140389308338800
	140389435998752 [label="transformer.layers.3.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389435998752 -> 140389435979424
	140389435979424 [label=AccumulateGrad]
	140389433321184 -> 140389433445248
	140389435998912 [label="transformer.layers.3.norm1.weight
 (44)" fillcolor=lightblue]
	140389435998912 -> 140389433321184
	140389433321184 [label=AccumulateGrad]
	140389433321232 -> 140389433445248
	140389435998432 [label="transformer.layers.3.norm1.bias
 (44)" fillcolor=lightblue]
	140389435998432 -> 140389433321232
	140389433321232 [label=AccumulateGrad]
	140389433445392 -> 140389433445584
	140389433445392 -> 140389348072864 [dir=none]
	140389348072864 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433445392 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433444960 -> 140389433445392
	140389433444960 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433444912 -> 140389433444960
	140389433444912 -> 140389348073344 [dir=none]
	140389348073344 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433444912 -> 140389348073184 [dir=none]
	140389348073184 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433444912 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389435979472 -> 140389433444912
	140389435998512 [label="transformer.layers.3.linear2.bias
 (44)" fillcolor=lightblue]
	140389435998512 -> 140389435979472
	140389435979472 [label=AccumulateGrad]
	140389308340912 -> 140389433444912
	140389308340912 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308338944 -> 140389308340912
	140389308338944 -> 140389348073104 [dir=none]
	140389348073104 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308338944 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308341536 -> 140389308338944
	140389308341536 -> 140389344096912 [dir=none]
	140389344096912 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308341536 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308342160 -> 140389308341536
	140389308342160 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308342928 -> 140389308342160
	140389308342928 -> 140389348073664 [dir=none]
	140389348073664 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308342928 -> 140389348073424 [dir=none]
	140389348073424 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308342928 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389429948672 -> 140389308342928
	140389435998352 [label="transformer.layers.3.linear1.bias
 (2048)" fillcolor=lightblue]
	140389435998352 -> 140389429948672
	140389429948672 [label=AccumulateGrad]
	140389308341248 -> 140389308342928
	140389308341248 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433445248 -> 140389308341248
	140389308342976 -> 140389308342928
	140389308342976 [label=TBackward0]
	140389429946560 -> 140389308342976
	140386168177744 [label="transformer.layers.3.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140386168177744 -> 140389429946560
	140389429946560 [label=AccumulateGrad]
	140389308339424 -> 140389433444912
	140389308339424 [label=TBackward0]
	140389435978704 -> 140389308339424
	140389435998672 [label="transformer.layers.3.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389435998672 -> 140389435978704
	140389435978704 [label=AccumulateGrad]
	140389433321808 -> 140389433445824
	140389435998992 [label="transformer.layers.3.norm2.weight
 (44)" fillcolor=lightblue]
	140389435998992 -> 140389433321808
	140389433321808 [label=AccumulateGrad]
	140389433321856 -> 140389433445824
	140389435998832 [label="transformer.layers.3.norm2.bias
 (44)" fillcolor=lightblue]
	140389435998832 -> 140389433321856
	140389433321856 [label=AccumulateGrad]
	140389433445872 -> 140389433445920
	140389433445872 -> 140389348073744 [dir=none]
	140389348073744 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433445872 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433445200 -> 140389433445872
	140389433445200 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433445152 -> 140389433445200
	140389433445152 -> 140389344099152 [dir=none]
	140389344099152 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433445152 -> 140389348073824 [dir=none]
	140389348073824 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433445152 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433321424 -> 140389433445152
	140389435999552 [label="transformer.layers.4.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389435999552 -> 140389433321424
	140389433321424 [label=AccumulateGrad]
	140389308342640 -> 140389433445152
	140389308342640 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308341008 -> 140389308342640
	140389308341008 [label=CloneBackward0]
	140389308341872 -> 140389308341008
	140389308341872 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308343264 -> 140389308341872
	140389308343264 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308343456 -> 140389308343264
	140389308343456 -> 140389348073904 [dir=none]
	140389348073904 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308343456 -> 140389348073584 [dir=none]
	140389348073584 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308343456 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308343552 -> 140389308343456
	140389308343552 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308343696 -> 140389308343552
	140389308343696 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308343792 -> 140389308343696
	140389308343792 -> 140389348073504 [dir=none]
	140389348073504 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308343792 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308343888 -> 140389308343792
	140389308343888 -> 140389348074064 [dir=none]
	140389348074064 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308343888 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308343984 -> 140389308343888
	140389308343984 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308344080 -> 140389308343984
	140389308344080 -> 140389348074224 [dir=none]
	140389348074224 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308344080 -> 140389348074304 [dir=none]
	140389348074304 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308344080 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308344176 -> 140389308344080
	140389308344176 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308344320 -> 140389308344176
	140389308344320 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308344416 -> 140389308344320
	140389308344416 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308344512 -> 140389308344416
	140389308344512 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308344608 -> 140389308344512
	140389308344608 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308344704 -> 140389308344608
	140389308344704 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308344800 -> 140389308344704
	140389308344800 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308344896 -> 140389308344800
	140389308344896 [label=CloneBackward0]
	140389308344992 -> 140389308344896
	140389308344992 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308345088 -> 140389308344992
	140389308345088 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308345232 -> 140389308345088
	140389308345232 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308345280 -> 140389308345232
	140389308345280 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308345424 -> 140389308345280
	140389308345424 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308345520 -> 140389308345424
	140389308345520 -> 140389348073984 [dir=none]
	140389348073984 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308345520 -> 140389348074544 [dir=none]
	140389348074544 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308345520 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389429941088 -> 140389308345520
	140389435999072 [label="transformer.layers.4.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389435999072 -> 140389429941088
	140389429941088 [label=AccumulateGrad]
	140389308345616 -> 140389308345520
	140389308345616 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433445824 -> 140389308345616
	140389308345568 -> 140389308345520
	140389308345568 [label=TBackward0]
	140389429940896 -> 140389308345568
	140389435999152 [label="transformer.layers.4.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389435999152 -> 140389429940896
	140389429940896 [label=AccumulateGrad]
	140389308344128 -> 140389308344080
	140389308344128 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308344464 -> 140389308344128
	140389308344464 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308344656 -> 140389308344464
	140389308344656 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308344848 -> 140389308344656
	140389308344848 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308345136 -> 140389308344848
	140389308345136 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308345184 -> 140389308345136
	140389308345184 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308345472 -> 140389308345184
	140389308345472 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308345760 -> 140389308345472
	140389308345760 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308344896 -> 140389308345760
	140389308343504 -> 140389308343456
	140389308343504 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308343840 -> 140389308343504
	140389308343840 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308344032 -> 140389308343840
	140389308344032 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308344368 -> 140389308344032
	140389308344368 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308344752 -> 140389308344368
	140389308344752 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308344944 -> 140389308344752
	140389308344944 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308344896 -> 140389308344944
	140389308341200 -> 140389433445152
	140389308341200 [label=TBackward0]
	140389429943872 -> 140389308341200
	140389435999712 [label="transformer.layers.4.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389435999712 -> 140389429943872
	140389429943872 [label=AccumulateGrad]
	140389433322192 -> 140389433446064
	140389435999872 [label="transformer.layers.4.norm1.weight
 (44)" fillcolor=lightblue]
	140389435999872 -> 140389433322192
	140389433322192 [label=AccumulateGrad]
	140389433322240 -> 140389433446064
	140389435999392 [label="transformer.layers.4.norm1.bias
 (44)" fillcolor=lightblue]
	140389435999392 -> 140389433322240
	140389433322240 [label=AccumulateGrad]
	140389433446112 -> 140389433446160
	140389433446112 -> 140389348074144 [dir=none]
	140389348074144 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433446112 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433445776 -> 140389433446112
	140389433445776 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433445632 -> 140389433445776
	140389433445632 -> 140389348074624 [dir=none]
	140389348074624 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433445632 -> 140389348074464 [dir=none]
	140389348074464 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433445632 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389429944064 -> 140389433445632
	140389435999472 [label="transformer.layers.4.linear2.bias
 (44)" fillcolor=lightblue]
	140389435999472 -> 140389429944064
	140389429944064 [label=AccumulateGrad]
	140389308343312 -> 140389433445632
	140389308343312 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308341344 -> 140389308343312
	140389308341344 -> 140389348074384 [dir=none]
	140389348074384 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308341344 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308343936 -> 140389308341344
	140389308343936 -> 140389344098912 [dir=none]
	140389344098912 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308343936 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308344560 -> 140389308343936
	140389308344560 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308345328 -> 140389308344560
	140389308345328 -> 140389348074944 [dir=none]
	140389348074944 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308345328 -> 140389348074704 [dir=none]
	140389348074704 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308345328 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389429940848 -> 140389308345328
	140389435999232 [label="transformer.layers.4.linear1.bias
 (2048)" fillcolor=lightblue]
	140389435999232 -> 140389429940848
	140389429940848 [label=AccumulateGrad]
	140389308343648 -> 140389308345328
	140389308343648 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433446064 -> 140389308343648
	140389308345376 -> 140389308345328
	140389308345376 [label=TBackward0]
	140389429940752 -> 140389308345376
	140389435999312 [label="transformer.layers.4.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389435999312 -> 140389429940752
	140389429940752 [label=AccumulateGrad]
	140389308341824 -> 140389433445632
	140389308341824 [label=TBackward0]
	140389429941664 -> 140389308341824
	140389435999632 [label="transformer.layers.4.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389435999632 -> 140389429941664
	140389429941664 [label=AccumulateGrad]
	140389433322576 -> 140389433446304
	140389435999952 [label="transformer.layers.4.norm2.weight
 (44)" fillcolor=lightblue]
	140389435999952 -> 140389433322576
	140389433322576 [label=AccumulateGrad]
	140389433322624 -> 140389433446304
	140389435999792 [label="transformer.layers.4.norm2.bias
 (44)" fillcolor=lightblue]
	140389435999792 -> 140389433322624
	140389433322624 [label=AccumulateGrad]
	140389433446448 -> 140389433446496
	140389433446448 -> 140389348075024 [dir=none]
	140389348075024 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433446448 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433446016 -> 140389433446448
	140389433446016 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433445968 -> 140389433446016
	140389433445968 -> 140389344096992 [dir=none]
	140389344096992 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433445968 -> 140389348075104 [dir=none]
	140389348075104 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433445968 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389429940800 -> 140389433445968
	140389436000512 [label="transformer.layers.5.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436000512 -> 140389429940800
	140389429940800 [label=AccumulateGrad]
	140389308345040 -> 140389433445968
	140389308345040 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308343408 -> 140389308345040
	140389308343408 [label=CloneBackward0]
	140389308344272 -> 140389308343408
	140389308344272 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308345664 -> 140389308344272
	140389308345664 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308345856 -> 140389308345664
	140389308345856 -> 140389348075184 [dir=none]
	140389348075184 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308345856 -> 140389348074864 [dir=none]
	140389348074864 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308345856 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308345952 -> 140389308345856
	140389308345952 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308346096 -> 140389308345952
	140389308346096 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308346192 -> 140389308346096
	140389308346192 -> 140389348074784 [dir=none]
	140389348074784 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308346192 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308346288 -> 140389308346192
	140389308346288 -> 140389348075344 [dir=none]
	140389348075344 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308346288 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308346384 -> 140389308346288
	140389308346384 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308346480 -> 140389308346384
	140389308346480 -> 140389348075504 [dir=none]
	140389348075504 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308346480 -> 140389348075584 [dir=none]
	140389348075584 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308346480 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308346576 -> 140389308346480
	140389308346576 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308346720 -> 140389308346576
	140389308346720 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308346816 -> 140389308346720
	140389308346816 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308346912 -> 140389308346816
	140389308346912 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308347008 -> 140389308346912
	140389308347008 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308347104 -> 140389308347008
	140389308347104 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308347200 -> 140389308347104
	140389308347200 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308347296 -> 140389308347200
	140389308347296 [label=CloneBackward0]
	140389308347392 -> 140389308347296
	140389308347392 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308347488 -> 140389308347392
	140389308347488 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308347632 -> 140389308347488
	140389308347632 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308347680 -> 140389308347632
	140389308347680 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308347824 -> 140389308347680
	140389308347824 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308347920 -> 140389308347824
	140389308347920 -> 140389348075264 [dir=none]
	140389348075264 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308347920 -> 140389348075824 [dir=none]
	140389348075824 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308347920 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389429938304 -> 140389308347920
	140389436000032 [label="transformer.layers.5.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436000032 -> 140389429938304
	140389429938304 [label=AccumulateGrad]
	140389308348016 -> 140389308347920
	140389308348016 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433446304 -> 140389308348016
	140389308347968 -> 140389308347920
	140389308347968 [label=TBackward0]
	140389429938112 -> 140389308347968
	140389436000112 [label="transformer.layers.5.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436000112 -> 140389429938112
	140389429938112 [label=AccumulateGrad]
	140389308346528 -> 140389308346480
	140389308346528 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308346864 -> 140389308346528
	140389308346864 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308347056 -> 140389308346864
	140389308347056 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308347248 -> 140389308347056
	140389308347248 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308347536 -> 140389308347248
	140389308347536 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308347584 -> 140389308347536
	140389308347584 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308347872 -> 140389308347584
	140389308347872 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308348160 -> 140389308347872
	140389308348160 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308347296 -> 140389308348160
	140389308345904 -> 140389308345856
	140389308345904 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308346240 -> 140389308345904
	140389308346240 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308346432 -> 140389308346240
	140389308346432 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308346768 -> 140389308346432
	140389308346768 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308347152 -> 140389308346768
	140389308347152 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308347344 -> 140389308347152
	140389308347344 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308347296 -> 140389308347344
	140389308343600 -> 140389433445968
	140389308343600 [label=TBackward0]
	140389429940608 -> 140389308343600
	140389436000672 [label="transformer.layers.5.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436000672 -> 140389429940608
	140389429940608 [label=AccumulateGrad]
	140389433322912 -> 140389433446640
	140389436000832 [label="transformer.layers.5.norm1.weight
 (44)" fillcolor=lightblue]
	140389436000832 -> 140389433322912
	140389433322912 [label=AccumulateGrad]
	140389433322960 -> 140389433446640
	140389436000352 [label="transformer.layers.5.norm1.bias
 (44)" fillcolor=lightblue]
	140389436000352 -> 140389433322960
	140389433322960 [label=AccumulateGrad]
	140389433446688 -> 140389433446784
	140389433446688 -> 140389348075424 [dir=none]
	140389348075424 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433446688 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433446256 -> 140389433446688
	140389433446256 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433446208 -> 140389433446256
	140389433446208 -> 140389348075904 [dir=none]
	140389348075904 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433446208 -> 140389348075744 [dir=none]
	140389348075744 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433446208 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389429940656 -> 140389433446208
	140389436000432 [label="transformer.layers.5.linear2.bias
 (44)" fillcolor=lightblue]
	140389436000432 -> 140389429940656
	140389429940656 [label=AccumulateGrad]
	140389308345712 -> 140389433446208
	140389308345712 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308343744 -> 140389308345712
	140389308343744 -> 140389348075664 [dir=none]
	140389348075664 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308343744 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308346336 -> 140389308343744
	140389308346336 -> 140389344099472 [dir=none]
	140389344099472 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308346336 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308346960 -> 140389308346336
	140389308346960 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308347728 -> 140389308346960
	140389308347728 -> 140389348076224 [dir=none]
	140389348076224 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308347728 -> 140389348075984 [dir=none]
	140389348075984 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308347728 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389429938064 -> 140389308347728
	140389436000192 [label="transformer.layers.5.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436000192 -> 140389429938064
	140389429938064 [label=AccumulateGrad]
	140389308346048 -> 140389308347728
	140389308346048 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433446640 -> 140389308346048
	140389308347776 -> 140389308347728
	140389308347776 [label=TBackward0]
	140389429937968 -> 140389308347776
	140389436000272 [label="transformer.layers.5.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436000272 -> 140389429937968
	140389429937968 [label=AccumulateGrad]
	140389308344224 -> 140389433446208
	140389308344224 [label=TBackward0]
	140389429938880 -> 140389308344224
	140389436000592 [label="transformer.layers.5.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436000592 -> 140389429938880
	140389429938880 [label=AccumulateGrad]
	140389433323248 -> 140389433446928
	140389436000912 [label="transformer.layers.5.norm2.weight
 (44)" fillcolor=lightblue]
	140389436000912 -> 140389433323248
	140389433323248 [label=AccumulateGrad]
	140389433323296 -> 140389433446928
	140389436000752 [label="transformer.layers.5.norm2.bias
 (44)" fillcolor=lightblue]
	140389436000752 -> 140389433323296
	140389433323296 [label=AccumulateGrad]
	140389433447072 -> 140389433447120
	140389433447072 -> 140389348076304 [dir=none]
	140389348076304 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433447072 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433446592 -> 140389433447072
	140389433446592 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433446544 -> 140389433446592
	140389433446544 -> 140389344097312 [dir=none]
	140389344097312 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433446544 -> 140389348076384 [dir=none]
	140389348076384 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433446544 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389429938016 -> 140389433446544
	140389436001472 [label="transformer.layers.6.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436001472 -> 140389429938016
	140389429938016 [label=AccumulateGrad]
	140389308347440 -> 140389433446544
	140389308347440 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308345808 -> 140389308347440
	140389308345808 [label=CloneBackward0]
	140389308346672 -> 140389308345808
	140389308346672 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308348064 -> 140389308346672
	140389308348064 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308348256 -> 140389308348064
	140389308348256 -> 140389348076464 [dir=none]
	140389348076464 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308348256 -> 140389348076144 [dir=none]
	140389348076144 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308348256 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308348352 -> 140389308348256
	140389308348352 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308348496 -> 140389308348352
	140389308348496 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308348592 -> 140389308348496
	140389308348592 -> 140389348076064 [dir=none]
	140389348076064 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308348592 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308348688 -> 140389308348592
	140389308348688 -> 140389348076624 [dir=none]
	140389348076624 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308348688 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308348784 -> 140389308348688
	140389308348784 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308348880 -> 140389308348784
	140389308348880 -> 140389348076784 [dir=none]
	140389348076784 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308348880 -> 140389348076864 [dir=none]
	140389348076864 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308348880 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308348976 -> 140389308348880
	140389308348976 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308349120 -> 140389308348976
	140389308349120 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308349216 -> 140389308349120
	140389308349216 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308349312 -> 140389308349216
	140389308349312 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308349408 -> 140389308349312
	140389308349408 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308349504 -> 140389308349408
	140389308349504 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308349600 -> 140389308349504
	140389308349600 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308349696 -> 140389308349600
	140389308349696 [label=CloneBackward0]
	140389308349792 -> 140389308349696
	140389308349792 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308349888 -> 140389308349792
	140389308349888 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308350032 -> 140389308349888
	140389308350032 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308350080 -> 140389308350032
	140389308350080 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308350224 -> 140389308350080
	140389308350224 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308350320 -> 140389308350224
	140389308350320 -> 140389348076544 [dir=none]
	140389348076544 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308350320 -> 140389348077104 [dir=none]
	140389348077104 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308350320 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389429951936 -> 140389308350320
	140389436000992 [label="transformer.layers.6.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436000992 -> 140389429951936
	140389429951936 [label=AccumulateGrad]
	140389308350416 -> 140389308350320
	140389308350416 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433446928 -> 140389308350416
	140389308350368 -> 140389308350320
	140389308350368 [label=TBackward0]
	140389429951744 -> 140389308350368
	140389436001072 [label="transformer.layers.6.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436001072 -> 140389429951744
	140389429951744 [label=AccumulateGrad]
	140389308348928 -> 140389308348880
	140389308348928 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308349264 -> 140389308348928
	140389308349264 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308349456 -> 140389308349264
	140389308349456 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308349648 -> 140389308349456
	140389308349648 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308349936 -> 140389308349648
	140389308349936 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308349984 -> 140389308349936
	140389308349984 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308350272 -> 140389308349984
	140389308350272 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308349024 -> 140389308350272
	140389308349024 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308349696 -> 140389308349024
	140389308348304 -> 140389308348256
	140389308348304 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308348640 -> 140389308348304
	140389308348640 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308348832 -> 140389308348640
	140389308348832 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308349168 -> 140389308348832
	140389308349168 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308349552 -> 140389308349168
	140389308349552 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308349744 -> 140389308349552
	140389308349744 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308349696 -> 140389308349744
	140389308346000 -> 140389433446544
	140389308346000 [label=TBackward0]
	140389429937824 -> 140389308346000
	140389436001632 [label="transformer.layers.6.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436001632 -> 140389429937824
	140389429937824 [label=AccumulateGrad]
	140389433323584 -> 140389433447264
	140389436001792 [label="transformer.layers.6.norm1.weight
 (44)" fillcolor=lightblue]
	140389436001792 -> 140389433323584
	140389433323584 [label=AccumulateGrad]
	140389433323632 -> 140389433447264
	140389436001312 [label="transformer.layers.6.norm1.bias
 (44)" fillcolor=lightblue]
	140389436001312 -> 140389433323632
	140389433323632 [label=AccumulateGrad]
	140389433447312 -> 140389433447360
	140389433447312 -> 140389348076704 [dir=none]
	140389348076704 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433447312 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433446880 -> 140389433447312
	140389433446880 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433446832 -> 140389433446880
	140389433446832 -> 140389348077184 [dir=none]
	140389348077184 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433446832 -> 140389348077024 [dir=none]
	140389348077024 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433446832 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389429937872 -> 140389433446832
	140389436001392 [label="transformer.layers.6.linear2.bias
 (44)" fillcolor=lightblue]
	140389436001392 -> 140389429937872
	140389429937872 [label=AccumulateGrad]
	140389308348112 -> 140389433446832
	140389308348112 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308346144 -> 140389308348112
	140389308346144 -> 140389348076944 [dir=none]
	140389348076944 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308346144 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308348736 -> 140389308346144
	140389308348736 -> 140389344097632 [dir=none]
	140389344097632 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308348736 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308349360 -> 140389308348736
	140389308349360 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308350128 -> 140389308349360
	140389308350128 -> 140389348077504 [dir=none]
	140389348077504 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308350128 -> 140389348077264 [dir=none]
	140389348077264 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308350128 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389429951696 -> 140389308350128
	140389436001152 [label="transformer.layers.6.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436001152 -> 140389429951696
	140389429951696 [label=AccumulateGrad]
	140389308348448 -> 140389308350128
	140389308348448 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433447264 -> 140389308348448
	140389308350176 -> 140389308350128
	140389308350176 [label=TBackward0]
	140389429951600 -> 140389308350176
	140389436001232 [label="transformer.layers.6.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436001232 -> 140389429951600
	140389429951600 [label=AccumulateGrad]
	140389308346624 -> 140389433446832
	140389308346624 [label=TBackward0]
	140389429943344 -> 140389308346624
	140389436001552 [label="transformer.layers.6.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436001552 -> 140389429943344
	140389429943344 [label=AccumulateGrad]
	140389433323920 -> 140389433447504
	140389436001872 [label="transformer.layers.6.norm2.weight
 (44)" fillcolor=lightblue]
	140389436001872 -> 140389433323920
	140389433323920 [label=AccumulateGrad]
	140389433323968 -> 140389433447504
	140389436001712 [label="transformer.layers.6.norm2.bias
 (44)" fillcolor=lightblue]
	140389436001712 -> 140389433323968
	140389433323968 [label=AccumulateGrad]
	140389433447552 -> 140389433447600
	140389433447552 -> 140389348077584 [dir=none]
	140389348077584 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433447552 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433447216 -> 140389433447552
	140389433447216 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433447168 -> 140389433447216
	140389433447168 -> 140389344091872 [dir=none]
	140389344091872 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433447168 -> 140389348077664 [dir=none]
	140389348077664 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433447168 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389429951648 -> 140389433447168
	140389436002432 [label="transformer.layers.7.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436002432 -> 140389429951648
	140389429951648 [label=AccumulateGrad]
	140389308349840 -> 140389433447168
	140389308349840 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308348208 -> 140389308349840
	140389308348208 [label=CloneBackward0]
	140389308349072 -> 140389308348208
	140389308349072 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308530848 -> 140389308349072
	140389308530848 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308530944 -> 140389308530848
	140389308530944 -> 140389348077744 [dir=none]
	140389348077744 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308530944 -> 140389348077424 [dir=none]
	140389348077424 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308530944 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308531040 -> 140389308530944
	140389308531040 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308531184 -> 140389308531040
	140389308531184 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308531280 -> 140389308531184
	140389308531280 -> 140389348077344 [dir=none]
	140389348077344 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308531280 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308531376 -> 140389308531280
	140389308531376 -> 140389348077904 [dir=none]
	140389348077904 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308531376 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308531472 -> 140389308531376
	140389308531472 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308531568 -> 140389308531472
	140389308531568 -> 140389348078064 [dir=none]
	140389348078064 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308531568 -> 140389348078144 [dir=none]
	140389348078144 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308531568 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308531664 -> 140389308531568
	140389308531664 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308531808 -> 140389308531664
	140389308531808 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308531904 -> 140389308531808
	140389308531904 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308532000 -> 140389308531904
	140389308532000 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308532096 -> 140389308532000
	140389308532096 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308532192 -> 140389308532096
	140389308532192 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308532288 -> 140389308532192
	140389308532288 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308532384 -> 140389308532288
	140389308532384 [label=CloneBackward0]
	140389308532480 -> 140389308532384
	140389308532480 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308532576 -> 140389308532480
	140389308532576 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308532720 -> 140389308532576
	140389308532720 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308532768 -> 140389308532720
	140389308532768 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308532912 -> 140389308532768
	140389308532912 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308533008 -> 140389308532912
	140389308533008 -> 140389348077824 [dir=none]
	140389348077824 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308533008 -> 140389348078384 [dir=none]
	140389348078384 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308533008 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389429948528 -> 140389308533008
	140389436001952 [label="transformer.layers.7.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436001952 -> 140389429948528
	140389429948528 [label=AccumulateGrad]
	140389308533104 -> 140389308533008
	140389308533104 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433447504 -> 140389308533104
	140389308533056 -> 140389308533008
	140389308533056 [label=TBackward0]
	140389429948336 -> 140389308533056
	140389436002032 [label="transformer.layers.7.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436002032 -> 140389429948336
	140389429948336 [label=AccumulateGrad]
	140389308531616 -> 140389308531568
	140389308531616 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308531952 -> 140389308531616
	140389308531952 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308532144 -> 140389308531952
	140389308532144 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308532336 -> 140389308532144
	140389308532336 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308532624 -> 140389308532336
	140389308532624 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308532672 -> 140389308532624
	140389308532672 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308532960 -> 140389308532672
	140389308532960 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308533248 -> 140389308532960
	140389308533248 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308532384 -> 140389308533248
	140389308530992 -> 140389308530944
	140389308530992 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308531328 -> 140389308530992
	140389308531328 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308531520 -> 140389308531328
	140389308531520 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308531856 -> 140389308531520
	140389308531856 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308532240 -> 140389308531856
	140389308532240 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308532432 -> 140389308532240
	140389308532432 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308532384 -> 140389308532432
	140389308348400 -> 140389433447168
	140389308348400 [label=TBackward0]
	140389429951456 -> 140389308348400
	140389436002592 [label="transformer.layers.7.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436002592 -> 140389429951456
	140389429951456 [label=AccumulateGrad]
	140389433324256 -> 140389433447744
	140389436002752 [label="transformer.layers.7.norm1.weight
 (44)" fillcolor=lightblue]
	140389436002752 -> 140389433324256
	140389433324256 [label=AccumulateGrad]
	140389433324304 -> 140389433447744
	140389436002272 [label="transformer.layers.7.norm1.bias
 (44)" fillcolor=lightblue]
	140389436002272 -> 140389433324304
	140389433324304 [label=AccumulateGrad]
	140389433447792 -> 140389433447840
	140389433447792 -> 140389348077984 [dir=none]
	140389348077984 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433447792 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433447456 -> 140389433447792
	140389433447456 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433447408 -> 140389433447456
	140389433447408 -> 140389348078464 [dir=none]
	140389348078464 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433447408 -> 140389348078304 [dir=none]
	140389348078304 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433447408 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389429951504 -> 140389433447408
	140389436002352 [label="transformer.layers.7.linear2.bias
 (44)" fillcolor=lightblue]
	140389436002352 -> 140389429951504
	140389429951504 [label=AccumulateGrad]
	140389308348544 -> 140389433447408
	140389308348544 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308530896 -> 140389308348544
	140389308530896 -> 140389348078224 [dir=none]
	140389348078224 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308530896 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308531424 -> 140389308530896
	140389308531424 -> 140389344091232 [dir=none]
	140389344091232 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308531424 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308532048 -> 140389308531424
	140389308532048 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308532816 -> 140389308532048
	140389308532816 -> 140389348078784 [dir=none]
	140389348078784 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308532816 -> 140389348078544 [dir=none]
	140389348078544 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308532816 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389429948240 -> 140389308532816
	140389436002112 [label="transformer.layers.7.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436002112 -> 140389429948240
	140389429948240 [label=AccumulateGrad]
	140389308531136 -> 140389308532816
	140389308531136 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433447744 -> 140389308531136
	140389308532864 -> 140389308532816
	140389308532864 [label=TBackward0]
	140389429948096 -> 140389308532864
	140389436002192 [label="transformer.layers.7.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436002192 -> 140389429948096
	140389429948096 [label=AccumulateGrad]
	140389308334240 -> 140389433447408
	140389308334240 [label=TBackward0]
	140389429949296 -> 140389308334240
	140389436002512 [label="transformer.layers.7.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436002512 -> 140389429949296
	140389429949296 [label=AccumulateGrad]
	140389433324592 -> 140389433447984
	140389436002832 [label="transformer.layers.7.norm2.weight
 (44)" fillcolor=lightblue]
	140389436002832 -> 140389433324592
	140389433324592 [label=AccumulateGrad]
	140389433324736 -> 140389433447984
	140389436002672 [label="transformer.layers.7.norm2.bias
 (44)" fillcolor=lightblue]
	140389436002672 -> 140389433324736
	140389433324736 [label=AccumulateGrad]
	140389433448032 -> 140389433448080
	140389433448032 -> 140389348078864 [dir=none]
	140389348078864 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433448032 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433447696 -> 140389433448032
	140389433447696 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389308335488 -> 140389433447696
	140389308335488 -> 140389344094432 [dir=none]
	140389344094432 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308335488 -> 140389348078944 [dir=none]
	140389348078944 [label="mat2
 (44, 44)" fillcolor=orange]
	140389308335488 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389429948144 -> 140389308335488
	140389436003392 [label="transformer.layers.8.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436003392 -> 140389429948144
	140389429948144 [label=AccumulateGrad]
	140389433447888 -> 140389308335488
	140389433447888 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308530800 -> 140389433447888
	140389308530800 [label=CloneBackward0]
	140389308531760 -> 140389308530800
	140389308531760 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308533152 -> 140389308531760
	140389308533152 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308533344 -> 140389308533152
	140389308533344 -> 140389348079024 [dir=none]
	140389348079024 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308533344 -> 140389348078704 [dir=none]
	140389348078704 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308533344 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308533440 -> 140389308533344
	140389308533440 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308533584 -> 140389308533440
	140389308533584 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308533680 -> 140389308533584
	140389308533680 -> 140389348078624 [dir=none]
	140389348078624 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308533680 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308533776 -> 140389308533680
	140389308533776 -> 140389348079184 [dir=none]
	140389348079184 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308533776 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308533872 -> 140389308533776
	140389308533872 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308533968 -> 140389308533872
	140389308533968 -> 140389348079344 [dir=none]
	140389348079344 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308533968 -> 140389348079424 [dir=none]
	140389348079424 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308533968 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308534064 -> 140389308533968
	140389308534064 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308534208 -> 140389308534064
	140389308534208 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308534304 -> 140389308534208
	140389308534304 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308534400 -> 140389308534304
	140389308534400 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308534496 -> 140389308534400
	140389308534496 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308534592 -> 140389308534496
	140389308534592 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308534688 -> 140389308534592
	140389308534688 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308534784 -> 140389308534688
	140389308534784 [label=CloneBackward0]
	140389308534880 -> 140389308534784
	140389308534880 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308534976 -> 140389308534880
	140389308534976 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308535120 -> 140389308534976
	140389308535120 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308535168 -> 140389308535120
	140389308535168 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308535312 -> 140389308535168
	140389308535312 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308535408 -> 140389308535312
	140389308535408 -> 140389348079104 [dir=none]
	140389348079104 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308535408 -> 140389348079664 [dir=none]
	140389348079664 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308535408 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389429945072 -> 140389308535408
	140389436002912 [label="transformer.layers.8.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436002912 -> 140389429945072
	140389429945072 [label=AccumulateGrad]
	140389308535504 -> 140389308535408
	140389308535504 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433447984 -> 140389308535504
	140389308535456 -> 140389308535408
	140389308535456 [label=TBackward0]
	140389429944880 -> 140389308535456
	140389436002992 [label="transformer.layers.8.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436002992 -> 140389429944880
	140389429944880 [label=AccumulateGrad]
	140389308534016 -> 140389308533968
	140389308534016 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308534352 -> 140389308534016
	140389308534352 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308534544 -> 140389308534352
	140389308534544 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308534736 -> 140389308534544
	140389308534736 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308535024 -> 140389308534736
	140389308535024 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308535072 -> 140389308535024
	140389308535072 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308535360 -> 140389308535072
	140389308535360 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308535648 -> 140389308535360
	140389308535648 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308534784 -> 140389308535648
	140389308533392 -> 140389308533344
	140389308533392 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308533728 -> 140389308533392
	140389308533728 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308533920 -> 140389308533728
	140389308533920 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308534256 -> 140389308533920
	140389308534256 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308534640 -> 140389308534256
	140389308534640 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308534832 -> 140389308534640
	140389308534832 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308534784 -> 140389308534832
	140389308532528 -> 140389308335488
	140389308532528 [label=TBackward0]
	140389429947904 -> 140389308532528
	140389436003552 [label="transformer.layers.8.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436003552 -> 140389429947904
	140389429947904 [label=AccumulateGrad]
	140389433325264 -> 140389433448224
	140389436003712 [label="transformer.layers.8.norm1.weight
 (44)" fillcolor=lightblue]
	140389436003712 -> 140389433325264
	140389433325264 [label=AccumulateGrad]
	140389433325312 -> 140389433448224
	140389436003232 [label="transformer.layers.8.norm1.bias
 (44)" fillcolor=lightblue]
	140389436003232 -> 140389433325312
	140389433325312 [label=AccumulateGrad]
	140389433448272 -> 140389433448320
	140389433448272 -> 140389348079264 [dir=none]
	140389348079264 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433448272 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433447936 -> 140389433448272
	140389433447936 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433447648 -> 140389433447936
	140389433447648 -> 140389348079744 [dir=none]
	140389348079744 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433447648 -> 140389348079584 [dir=none]
	140389348079584 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433447648 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389429947952 -> 140389433447648
	140389436003312 [label="transformer.layers.8.linear2.bias
 (44)" fillcolor=lightblue]
	140389436003312 -> 140389429947952
	140389429947952 [label=AccumulateGrad]
	140389308533200 -> 140389433447648
	140389308533200 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308531232 -> 140389308533200
	140389308531232 -> 140389348079504 [dir=none]
	140389348079504 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308531232 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308533824 -> 140389308531232
	140389308533824 -> 140389344094032 [dir=none]
	140389344094032 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308533824 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308534448 -> 140389308533824
	140389308534448 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308535216 -> 140389308534448
	140389308535216 -> 140389348080064 [dir=none]
	140389348080064 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308535216 -> 140389348079824 [dir=none]
	140389348079824 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308535216 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389429944784 -> 140389308535216
	140389436003072 [label="transformer.layers.8.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436003072 -> 140389429944784
	140389429944784 [label=AccumulateGrad]
	140389308533536 -> 140389308535216
	140389308533536 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433448224 -> 140389308533536
	140389308535264 -> 140389308535216
	140389308535264 [label=TBackward0]
	140389429944688 -> 140389308535264
	140389436003152 [label="transformer.layers.8.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436003152 -> 140389429944688
	140389429944688 [label=AccumulateGrad]
	140389308531712 -> 140389433447648
	140389308531712 [label=TBackward0]
	140389429945696 -> 140389308531712
	140389436003472 [label="transformer.layers.8.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436003472 -> 140389429945696
	140389429945696 [label=AccumulateGrad]
	140389433325600 -> 140389433448512
	140389436003792 [label="transformer.layers.8.norm2.weight
 (44)" fillcolor=lightblue]
	140389436003792 -> 140389433325600
	140389433325600 [label=AccumulateGrad]
	140389433325648 -> 140389433448512
	140389436003632 [label="transformer.layers.8.norm2.bias
 (44)" fillcolor=lightblue]
	140389436003632 -> 140389433325648
	140389433325648 [label=AccumulateGrad]
	140389433448560 -> 140389433448656
	140389433448560 -> 140389348080144 [dir=none]
	140389348080144 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433448560 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433448176 -> 140389433448560
	140389433448176 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433448128 -> 140389433448176
	140389433448128 -> 140389344092912 [dir=none]
	140389344092912 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433448128 -> 140389348080224 [dir=none]
	140389348080224 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433448128 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389429944736 -> 140389433448128
	140389436004352 [label="transformer.layers.9.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436004352 -> 140389429944736
	140389429944736 [label=AccumulateGrad]
	140389308534928 -> 140389433448128
	140389308534928 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308533296 -> 140389308534928
	140389308533296 [label=CloneBackward0]
	140389308534160 -> 140389308533296
	140389308534160 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308535552 -> 140389308534160
	140389308535552 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308535744 -> 140389308535552
	140389308535744 -> 140389348080304 [dir=none]
	140389348080304 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308535744 -> 140389348079984 [dir=none]
	140389348079984 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308535744 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308535840 -> 140389308535744
	140389308535840 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308535984 -> 140389308535840
	140389308535984 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308536080 -> 140389308535984
	140389308536080 -> 140389348079904 [dir=none]
	140389348079904 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308536080 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308536176 -> 140389308536080
	140389308536176 -> 140389348080464 [dir=none]
	140389348080464 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308536176 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308536272 -> 140389308536176
	140389308536272 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308536368 -> 140389308536272
	140389308536368 -> 140389348080624 [dir=none]
	140389348080624 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308536368 -> 140389348080704 [dir=none]
	140389348080704 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308536368 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308536464 -> 140389308536368
	140389308536464 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308536608 -> 140389308536464
	140389308536608 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308536704 -> 140389308536608
	140389308536704 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308536800 -> 140389308536704
	140389308536800 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308536896 -> 140389308536800
	140389308536896 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308536992 -> 140389308536896
	140389308536992 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308537088 -> 140389308536992
	140389308537088 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308537184 -> 140389308537088
	140389308537184 [label=CloneBackward0]
	140389308537280 -> 140389308537184
	140389308537280 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308537376 -> 140389308537280
	140389308537376 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308537520 -> 140389308537376
	140389308537520 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308537568 -> 140389308537520
	140389308537568 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308537712 -> 140389308537568
	140389308537712 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308537808 -> 140389308537712
	140389308537808 -> 140389348080384 [dir=none]
	140389348080384 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308537808 -> 140389348080944 [dir=none]
	140389348080944 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308537808 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389433451392 -> 140389308537808
	140389436003872 [label="transformer.layers.9.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436003872 -> 140389433451392
	140389433451392 [label=AccumulateGrad]
	140389308537904 -> 140389308537808
	140389308537904 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433448512 -> 140389308537904
	140389308537856 -> 140389308537808
	140389308537856 [label=TBackward0]
	140389433450768 -> 140389308537856
	140389436003952 [label="transformer.layers.9.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436003952 -> 140389433450768
	140389433450768 [label=AccumulateGrad]
	140389308536416 -> 140389308536368
	140389308536416 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308536752 -> 140389308536416
	140389308536752 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308536944 -> 140389308536752
	140389308536944 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308537136 -> 140389308536944
	140389308537136 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308537424 -> 140389308537136
	140389308537424 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308537472 -> 140389308537424
	140389308537472 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308537760 -> 140389308537472
	140389308537760 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308538048 -> 140389308537760
	140389308538048 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308537184 -> 140389308538048
	140389308535792 -> 140389308535744
	140389308535792 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308536128 -> 140389308535792
	140389308536128 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308536320 -> 140389308536128
	140389308536320 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308536656 -> 140389308536320
	140389308536656 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308537040 -> 140389308536656
	140389308537040 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308537232 -> 140389308537040
	140389308537232 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308537184 -> 140389308537232
	140389308533488 -> 140389433448128
	140389308533488 [label=TBackward0]
	140389429944496 -> 140389308533488
	140389436004512 [label="transformer.layers.9.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436004512 -> 140389429944496
	140389429944496 [label=AccumulateGrad]
	140389433325984 -> 140389433448800
	140389436004672 [label="transformer.layers.9.norm1.weight
 (44)" fillcolor=lightblue]
	140389436004672 -> 140389433325984
	140389433325984 [label=AccumulateGrad]
	140389433326032 -> 140389433448800
	140389436004192 [label="transformer.layers.9.norm1.bias
 (44)" fillcolor=lightblue]
	140389436004192 -> 140389433326032
	140389433326032 [label=AccumulateGrad]
	140389433448896 -> 140389433448944
	140389433448896 -> 140389348080544 [dir=none]
	140389348080544 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433448896 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433448416 -> 140389433448896
	140389433448416 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433448368 -> 140389433448416
	140389433448368 -> 140389348081024 [dir=none]
	140389348081024 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433448368 -> 140389348080864 [dir=none]
	140389348080864 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433448368 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389429944544 -> 140389433448368
	140389436004272 [label="transformer.layers.9.linear2.bias
 (44)" fillcolor=lightblue]
	140389436004272 -> 140389429944544
	140389429944544 [label=AccumulateGrad]
	140389308535600 -> 140389433448368
	140389308535600 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308533632 -> 140389308535600
	140389308533632 -> 140389348080784 [dir=none]
	140389348080784 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308533632 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308536224 -> 140389308533632
	140389308536224 -> 140389344094272 [dir=none]
	140389344094272 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308536224 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308536848 -> 140389308536224
	140389308536848 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308537616 -> 140389308536848
	140389308537616 -> 140389348081344 [dir=none]
	140389348081344 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308537616 -> 140389348081104 [dir=none]
	140389348081104 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308537616 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389433450720 -> 140389308537616
	140389436004032 [label="transformer.layers.9.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436004032 -> 140389433450720
	140389433450720 [label=AccumulateGrad]
	140389308535936 -> 140389308537616
	140389308535936 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433448800 -> 140389308535936
	140389308537664 -> 140389308537616
	140389308537664 [label=TBackward0]
	140389433450384 -> 140389308537664
	140389436004112 [label="transformer.layers.9.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436004112 -> 140389433450384
	140389433450384 [label=AccumulateGrad]
	140389308534112 -> 140389433448368
	140389308534112 [label=TBackward0]
	140389433453504 -> 140389308534112
	140389436004432 [label="transformer.layers.9.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436004432 -> 140389433453504
	140389433453504 [label=AccumulateGrad]
	140389433326320 -> 140389433449088
	140389436004752 [label="transformer.layers.9.norm2.weight
 (44)" fillcolor=lightblue]
	140389436004752 -> 140389433326320
	140389433326320 [label=AccumulateGrad]
	140389433326368 -> 140389433449088
	140389436004592 [label="transformer.layers.9.norm2.bias
 (44)" fillcolor=lightblue]
	140389436004592 -> 140389433326368
	140389433326368 [label=AccumulateGrad]
	140389433449136 -> 140389433449184
	140389433449136 -> 140389348081424 [dir=none]
	140389348081424 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433449136 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433448752 -> 140389433449136
	140389433448752 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433448704 -> 140389433448752
	140389433448704 -> 140389344090192 [dir=none]
	140389344090192 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433448704 -> 140389348081504 [dir=none]
	140389348081504 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433448704 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433326224 -> 140389433448704
	140389436005312 [label="transformer.layers.10.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436005312 -> 140389433326224
	140389433326224 [label=AccumulateGrad]
	140389308537328 -> 140389433448704
	140389308537328 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308535696 -> 140389308537328
	140389308535696 [label=CloneBackward0]
	140389308536560 -> 140389308535696
	140389308536560 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308537952 -> 140389308536560
	140389308537952 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308538144 -> 140389308537952
	140389308538144 -> 140389348081184 [dir=none]
	140389348081184 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308538144 -> 140389348081584 [dir=none]
	140389348081584 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308538144 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308538240 -> 140389308538144
	140389308538240 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308538384 -> 140389308538240
	140389308538384 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308538480 -> 140389308538384
	140389308538480 -> 140389348081264 [dir=none]
	140389348081264 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308538480 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308538576 -> 140389308538480
	140389308538576 -> 140389308612752 [dir=none]
	140389308612752 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308538576 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308538672 -> 140389308538576
	140389308538672 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308538768 -> 140389308538672
	140389308538768 -> 140389308612912 [dir=none]
	140389308612912 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308538768 -> 140389308612992 [dir=none]
	140389308612992 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308538768 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308538864 -> 140389308538768
	140389308538864 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308539008 -> 140389308538864
	140389308539008 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308539104 -> 140389308539008
	140389308539104 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308539200 -> 140389308539104
	140389308539200 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308539296 -> 140389308539200
	140389308539296 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308539392 -> 140389308539296
	140389308539392 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308539488 -> 140389308539392
	140389308539488 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308539584 -> 140389308539488
	140389308539584 [label=CloneBackward0]
	140389308539680 -> 140389308539584
	140389308539680 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308539776 -> 140389308539680
	140389308539776 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308539920 -> 140389308539776
	140389308539920 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308539968 -> 140389308539920
	140389308539968 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308540112 -> 140389308539968
	140389308540112 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308540208 -> 140389308540112
	140389308540208 -> 140389308612832 [dir=none]
	140389308612832 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308540208 -> 140389308613232 [dir=none]
	140389308613232 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308540208 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389433457824 -> 140389308540208
	140389436004832 [label="transformer.layers.10.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436004832 -> 140389433457824
	140389433457824 [label=AccumulateGrad]
	140389308540304 -> 140389308540208
	140389308540304 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433449088 -> 140389308540304
	140389308540256 -> 140389308540208
	140389308540256 [label=TBackward0]
	140389433457488 -> 140389308540256
	140389436004912 [label="transformer.layers.10.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436004912 -> 140389433457488
	140389433457488 [label=AccumulateGrad]
	140389308538816 -> 140389308538768
	140389308538816 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308539152 -> 140389308538816
	140389308539152 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308539344 -> 140389308539152
	140389308539344 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308539536 -> 140389308539344
	140389308539536 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308539824 -> 140389308539536
	140389308539824 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308539872 -> 140389308539824
	140389308539872 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308540160 -> 140389308539872
	140389308540160 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308540448 -> 140389308540160
	140389308540448 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308539584 -> 140389308540448
	140389308538192 -> 140389308538144
	140389308538192 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308538528 -> 140389308538192
	140389308538528 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308538720 -> 140389308538528
	140389308538720 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308539056 -> 140389308538720
	140389308539056 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308539440 -> 140389308539056
	140389308539440 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308539632 -> 140389308539440
	140389308539632 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308539584 -> 140389308539632
	140389308535888 -> 140389433448704
	140389308535888 [label=TBackward0]
	140389433449472 -> 140389308535888
	140389436005472 [label="transformer.layers.10.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436005472 -> 140389433449472
	140389433449472 [label=AccumulateGrad]
	140389433326656 -> 140389433449328
	140389436005632 [label="transformer.layers.10.norm1.weight
 (44)" fillcolor=lightblue]
	140389436005632 -> 140389433326656
	140389433326656 [label=AccumulateGrad]
	140389433326704 -> 140389433449328
	140389436005152 [label="transformer.layers.10.norm1.bias
 (44)" fillcolor=lightblue]
	140389436005152 -> 140389433326704
	140389433326704 [label=AccumulateGrad]
	140389433449376 -> 140389433449520
	140389433449376 -> 140389308612672 [dir=none]
	140389308612672 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433449376 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433449040 -> 140389433449376
	140389433449040 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433448992 -> 140389433449040
	140389433448992 -> 140389308613312 [dir=none]
	140389308613312 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433448992 -> 140389308613152 [dir=none]
	140389308613152 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433448992 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389433450048 -> 140389433448992
	140389436005232 [label="transformer.layers.10.linear2.bias
 (44)" fillcolor=lightblue]
	140389436005232 -> 140389433450048
	140389433450048 [label=AccumulateGrad]
	140389308538000 -> 140389433448992
	140389308538000 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308536032 -> 140389308538000
	140389308536032 -> 140389308613072 [dir=none]
	140389308613072 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308536032 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308538624 -> 140389308536032
	140389308538624 -> 140389344089392 [dir=none]
	140389344089392 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308538624 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308539248 -> 140389308538624
	140389308539248 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308540016 -> 140389308539248
	140389308540016 -> 140389308613632 [dir=none]
	140389308613632 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308540016 -> 140389308613392 [dir=none]
	140389308613392 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308540016 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389433457440 -> 140389308540016
	140389436004992 [label="transformer.layers.10.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436004992 -> 140389433457440
	140389433457440 [label=AccumulateGrad]
	140389308538336 -> 140389308540016
	140389308538336 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433449328 -> 140389308538336
	140389308540064 -> 140389308540016
	140389308540064 [label=TBackward0]
	140389433457248 -> 140389308540064
	140389436005072 [label="transformer.layers.10.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436005072 -> 140389433457248
	140389433457248 [label=AccumulateGrad]
	140389308536512 -> 140389433448992
	140389308536512 [label=TBackward0]
	140389433457968 -> 140389308536512
	140389436005392 [label="transformer.layers.10.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436005392 -> 140389433457968
	140389433457968 [label=AccumulateGrad]
	140389433326992 -> 140389433449712
	140389436005712 [label="transformer.layers.10.norm2.weight
 (44)" fillcolor=lightblue]
	140389436005712 -> 140389433326992
	140389433326992 [label=AccumulateGrad]
	140389433327040 -> 140389433449712
	140389436005552 [label="transformer.layers.10.norm2.bias
 (44)" fillcolor=lightblue]
	140389436005552 -> 140389433327040
	140389433327040 [label=AccumulateGrad]
	140389433449808 -> 140389433449856
	140389433449808 -> 140389308613712 [dir=none]
	140389308613712 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433449808 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433449280 -> 140389433449808
	140389433449280 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433449232 -> 140389433449280
	140389433449232 -> 140389344092192 [dir=none]
	140389344092192 [label="mat1
 (16, 44)" fillcolor=orange]
	140389433449232 -> 140389308613792 [dir=none]
	140389308613792 [label="mat2
 (44, 44)" fillcolor=orange]
	140389433449232 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (44, 44)
mat2_sym_strides:        (1, 44)"]
	140389433457392 -> 140389433449232
	140389436006272 [label="transformer.layers.11.self_attn.out_proj.bias
 (44)" fillcolor=lightblue]
	140389436006272 -> 140389433457392
	140389433457392 [label=AccumulateGrad]
	140389308539728 -> 140389433449232
	140389308539728 [label="ViewBackward0
-----------------------------
self_sym_sizes: (2, 8, 11, 4)"]
	140389308538096 -> 140389308539728
	140389308538096 [label=CloneBackward0]
	140389308538960 -> 140389308538096
	140389308538960 [label="PermuteBackward0
------------------
dims: (2, 0, 1, 3)"]
	140389308540352 -> 140389308538960
	140389308540352 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308540544 -> 140389308540352
	140389308540544 -> 140389308613872 [dir=none]
	140389308613872 [label="mat2
 (88, 2, 4)" fillcolor=orange]
	140389308540544 -> 140389308613552 [dir=none]
	140389308613552 [label="self
 (88, 2, 2)" fillcolor=orange]
	140389308540544 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308540640 -> 140389308540544
	140389308540640 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308540784 -> 140389308540640
	140389308540784 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 2)"]
	140389308540880 -> 140389308540784
	140389308540880 -> 140389308613472 [dir=none]
	140389308613472 [label="result1
 (8, 11, 2, 2)" fillcolor=orange]
	140389308540880 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308540976 -> 140389308540880
	140389308540976 -> 140389308614032 [dir=none]
	140389308614032 [label="result
 (8, 11, 2, 2)" fillcolor=orange]
	140389308540976 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140389308541072 -> 140389308540976
	140389308541072 [label="UnsafeViewBackward0
--------------------------
self_sym_sizes: (88, 2, 2)"]
	140389308541168 -> 140389308541072
	140389308541168 -> 140389308614192 [dir=none]
	140389308614192 [label="mat2
 (88, 4, 2)" fillcolor=orange]
	140389308541168 -> 140389308614272 [dir=none]
	140389308614272 [label="self
 (88, 2, 4)" fillcolor=orange]
	140389308541168 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308541264 -> 140389308541168
	140389308541264 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308541408 -> 140389308541264
	140389308541408 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308541504 -> 140389308541408
	140389308541504 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308541600 -> 140389308541504
	140389308541600 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308541696 -> 140389308541600
	140389308541696 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308541792 -> 140389308541696
	140389308541792 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308541888 -> 140389308541792
	140389308541888 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             0
self_sym_sizes: (3, 2, 8, 44)"]
	140389308541984 -> 140389308541888
	140389308541984 [label=CloneBackward0]
	140389308542080 -> 140389308541984
	140389308542080 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551614
self_sym_sizes:     (3, 2, 8, 1, 44)"]
	140389308542176 -> 140389308542080
	140389308542176 [label="TransposeBackward0
--------------------------
dim0:                    0
dim1: 18446744073709551614"]
	140389308542320 -> 140389308542176
	140389308542320 [label="UnsqueezeBackward0
------------------
dim: 0"]
	140389308542368 -> 140389308542320
	140389308542368 [label="ViewBackward0
---------------------------
self_sym_sizes: (2, 8, 132)"]
	140389308542512 -> 140389308542368
	140389308542512 [label="ViewBackward0
-------------------------
self_sym_sizes: (16, 132)"]
	140389308542608 -> 140389308542512
	140389308542608 -> 140389308613952 [dir=none]
	140389308613952 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308542608 -> 140389308614512 [dir=none]
	140389308614512 [label="mat2
 (44, 132)" fillcolor=orange]
	140389308542608 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (44, 132)
mat2_sym_strides:        (1, 44)"]
	140389433453408 -> 140389308542608
	140389436005792 [label="transformer.layers.11.self_attn.in_proj_bias
 (132)" fillcolor=lightblue]
	140389436005792 -> 140389433453408
	140389433453408 [label=AccumulateGrad]
	140389308542704 -> 140389308542608
	140389308542704 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433449712 -> 140389308542704
	140389308542656 -> 140389308542608
	140389308542656 [label=TBackward0]
	140389433453216 -> 140389308542656
	140389436005872 [label="transformer.layers.11.self_attn.in_proj_weight
 (132, 44)" fillcolor=lightblue]
	140389436005872 -> 140389433453216
	140389433453216 [label=AccumulateGrad]
	140389308541216 -> 140389308541168
	140389308541216 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308541552 -> 140389308541216
	140389308541552 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 4, 2)"]
	140389308541744 -> 140389308541552
	140389308541744 [label="DivBackward1
-------------------------
other: 1.4142135623730951"]
	140389308541936 -> 140389308541744
	140389308541936 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	140389308542224 -> 140389308541936
	140389308542224 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308542272 -> 140389308542224
	140389308542272 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308542560 -> 140389308542272
	140389308542560 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308542848 -> 140389308542560
	140389308542848 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             1
self_sym_sizes: (3, 2, 8, 44)"]
	140389308541984 -> 140389308542848
	140389308540592 -> 140389308540544
	140389308540592 [label="ReshapeAliasBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308540928 -> 140389308540592
	140389308540928 [label="ExpandBackward0
-----------------------------
self_sym_sizes: (8, 11, 2, 4)"]
	140389308541120 -> 140389308540928
	140389308541120 [label="ViewBackward0
--------------------------
self_sym_sizes: (88, 2, 4)"]
	140389308541456 -> 140389308541120
	140389308541456 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	140389308541840 -> 140389308541456
	140389308541840 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389308542032 -> 140389308541840
	140389308542032 [label="SelectBackward0
-----------------------------
dim           :             0
index         :             2
self_sym_sizes: (3, 2, 8, 44)"]
	140389308541984 -> 140389308542032
	140389308538288 -> 140389433449232
	140389308538288 [label=TBackward0]
	140389433457056 -> 140389308538288
	140389436006432 [label="transformer.layers.11.self_attn.out_proj.weight
 (44, 44)" fillcolor=lightblue]
	140389436006432 -> 140389433457056
	140389433457056 [label=AccumulateGrad]
	140389433327376 -> 140389433450000
	140389436006592 [label="transformer.layers.11.norm1.weight
 (44)" fillcolor=lightblue]
	140389436006592 -> 140389433327376
	140389433327376 [label=AccumulateGrad]
	140389433327424 -> 140389433450000
	140389436006112 [label="transformer.layers.11.norm1.bias
 (44)" fillcolor=lightblue]
	140389436006112 -> 140389433327424
	140389433327424 [label=AccumulateGrad]
	140389433450144 -> 140389433450192
	140389433450144 -> 140389308614112 [dir=none]
	140389308614112 [label="result1
 (2, 8, 44)" fillcolor=orange]
	140389433450144 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389433449664 -> 140389433450144
	140389433449664 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 44)"]
	140389433449616 -> 140389433449664
	140389433449616 -> 140389308614592 [dir=none]
	140389308614592 [label="mat1
 (16, 2048)" fillcolor=orange]
	140389433449616 -> 140389308614432 [dir=none]
	140389308614432 [label="mat2
 (2048, 44)" fillcolor=orange]
	140389433449616 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (16, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (2048, 44)
mat2_sym_strides:      (1, 2048)"]
	140389433457104 -> 140389433449616
	140389436006192 [label="transformer.layers.11.linear2.bias
 (44)" fillcolor=lightblue]
	140389436006192 -> 140389433457104
	140389433457104 [label=AccumulateGrad]
	140389308540400 -> 140389433449616
	140389308540400 [label="ViewBackward0
----------------------------
self_sym_sizes: (2, 8, 2048)"]
	140389308538432 -> 140389308540400
	140389308538432 -> 140389308614352 [dir=none]
	140389308614352 [label="result1
 (2, 8, 2048)" fillcolor=orange]
	140389308538432 [label="NativeDropoutBackward0
-----------------------
p      :            0.1
result1: [saved tensor]"]
	140389308541024 -> 140389308538432
	140389308541024 -> 140389344089712 [dir=none]
	140389344089712 [label="self
 (2, 8, 2048)" fillcolor=orange]
	140389308541024 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308541648 -> 140389308541024
	140389308541648 [label="ViewBackward0
--------------------------
self_sym_sizes: (16, 2048)"]
	140389308542416 -> 140389308541648
	140389308542416 -> 140389308614912 [dir=none]
	140389308614912 [label="mat1
 (16, 44)" fillcolor=orange]
	140389308542416 -> 140389308614672 [dir=none]
	140389308614672 [label="mat2
 (44, 2048)" fillcolor=orange]
	140389308542416 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 44)
mat1_sym_strides:        (44, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (44, 2048)
mat2_sym_strides:        (1, 44)"]
	140389433453072 -> 140389308542416
	140389436005952 [label="transformer.layers.11.linear1.bias
 (2048)" fillcolor=lightblue]
	140389436005952 -> 140389433453072
	140389433453072 [label=AccumulateGrad]
	140389308540736 -> 140389308542416
	140389308540736 [label="ViewBackward0
--------------------------
self_sym_sizes: (2, 8, 44)"]
	140389433450000 -> 140389308540736
	140389308542464 -> 140389308542416
	140389308542464 [label=TBackward0]
	140389433452976 -> 140389308542464
	140389436006032 [label="transformer.layers.11.linear1.weight
 (2048, 44)" fillcolor=lightblue]
	140389436006032 -> 140389433452976
	140389433452976 [label=AccumulateGrad]
	140389308538912 -> 140389433449616
	140389308538912 [label=TBackward0]
	140389433454272 -> 140389308538912
	140389436006352 [label="transformer.layers.11.linear2.weight
 (44, 2048)" fillcolor=lightblue]
	140389436006352 -> 140389433454272
	140389433454272 [label=AccumulateGrad]
	140389433312304 -> 140389433450288
	140389436006672 [label="transformer.layers.11.norm2.weight
 (44)" fillcolor=lightblue]
	140389436006672 -> 140389433312304
	140389433312304 [label=AccumulateGrad]
	140389433312352 -> 140389433450288
	140389436006512 [label="transformer.layers.11.norm2.bias
 (44)" fillcolor=lightblue]
	140389436006512 -> 140389433312352
	140389433312352 [label=AccumulateGrad]
	140389433313024 -> 140389433450480
	140386053698112 [label="transformer.norm.weight
 (44)" fillcolor=lightblue]
	140386053698112 -> 140389433313024
	140389433313024 [label=AccumulateGrad]
	140389433321712 -> 140389433450480
	140386053698672 [label="transformer.norm.bias
 (44)" fillcolor=lightblue]
	140386053698672 -> 140389433321712
	140389433321712 [label=AccumulateGrad]
	140389433456336 -> 140389433452352
	140389433456336 [label="SqueezeBackward1
------------------------------------
dim           : 18446744073709551615
self_sym_sizes:            (2, 4, 1)"]
	140389433451872 -> 140389433456336
	140389433451872 [label="UnsafeViewBackward0
-------------------------
self_sym_sizes: (2, 4, 1)"]
	140389433451488 -> 140389433451872
	140389433451488 -> 140389308614992 [dir=none]
	140389308614992 [label="mat2
 (2, 4, 1)" fillcolor=orange]
	140389433451488 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self:           None"]
	140389433451200 -> 140389433451488
	140389433451200 [label="ReshapeAliasBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389433450816 -> 140389433451200
	140389433450816 [label="ExpandBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389433450528 -> 140389433450816
	140389433450528 -> 140389308614832 [dir=none]
	140389308614832 [label="L
 (2, 4, 4)" fillcolor=orange]
	140389433450528 [label="LinalgCholeskyExBackward0
-------------------------
L    : [saved tensor]
upper:          False"]
	140389433450240 -> 140389433450528
	140389433450240 [label="AddBackward0
------------
alpha: 1"]
	140389433449952 -> 140389433450240
	140389433449952 [label="UnsafeViewBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389433449904 -> 140389433449952
	140389433449904 -> 140389308615072 [dir=none]
	140389308615072 [label="mat2
 (2, 4, 4)" fillcolor=orange]
	140389433449904 -> 140389308615152 [dir=none]
	140389308615152 [label="self
 (2, 4, 4)" fillcolor=orange]
	140389433449904 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	140389308542128 -> 140389433449904
	140389308542128 [label="ReshapeAliasBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389308530752 -> 140389308542128
	140389308530752 [label="ExpandBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389308541360 -> 140389308530752
	140389308541360 -> 140389344090112 [dir=none]
	140389344090112 [label="self
 (2, 4, 4)" fillcolor=orange]
	140389308541360 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140389308542752 -> 140389308541360
	140389308542752 [label="ReshapeAliasBackward0
--------------------------
self_sym_sizes: (2, 1, 16)"]
	140389308542944 -> 140389308542752
	140389308542944 [label="SliceBackward0
-----------------------------------
dim           :                   2
end           : 9223372036854775807
self_sym_sizes:          (2, 1, 20)
start         :                   4
step          :                   1"]
	140389308543040 -> 140389308542944
	140389308543040 [label="SliceBackward0
-----------------------------------
dim           :                   1
end           : 9223372036854775807
self_sym_sizes:          (2, 1, 20)
start         :                   0
step          :                   1"]
	140389308543136 -> 140389308543040
	140389308543136 [label="SliceBackward0
-----------------------------------
dim           :                   0
end           : 9223372036854775807
self_sym_sizes:          (2, 1, 20)
start         :                   0
step          :                   1"]
	140389433451248 -> 140389308543136
	140389308540688 -> 140389433449904
	140389308540688 [label="ReshapeAliasBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389308541312 -> 140389308540688
	140389308541312 [label="ExpandBackward0
-------------------------
self_sym_sizes: (2, 4, 4)"]
	140389308542992 -> 140389308541312
	140389308542992 [label="PermuteBackward0
----------------
dims: (0, 2, 1)"]
	140389308541360 -> 140389308542992
	140389433452112 -> 140389348185952
}
